{
  "level": "junior",
  "type": "生成式AI應用與規劃",
  "quiz_id": "114-AI-Subject2-MockExam10",
  "title": "114年初級AI應用規劃師第二科：生成式AI應用與規劃 (模擬考卷十)",
  "exam_date": "2025-11-01",
  "questions": [
    {
      "id": "q1",
      "type": "single_choice",
      "questionText": "No Code / Low Code 平台賦予非技術背景的人員利用視覺化工具自行開發自動化流程的能力。這些非技術背景的開發者在業界常被稱為什麼？",
      "options": [
        { "key": "A", "value": "系統架構師 (System Architect)" },
        { "key": "B", "value": "市民開發者 (Citizen Developer)" },
        { "key": "C", "value": "全端工程師 (Full-stack Developer)" },
        { "key": "D", "value": "資料科學家 (Data Scientist)" }
      ],
      "answer": "B",
      "explanation": "No Code / Low Code 平台將技術力量擴展到非技術背景的個人與企業，這些人員被稱為「市民開發者 (Citizen Developer)」，能利用工具自動化日常工作，提高生產力 [1]。",
      "score": 2,
      "tags": ["No code / Low code", "市民開發者"]
    },
    {
      "id": "q2",
      "type": "single_choice",
      "questionText": "「AI 民主化 (AI Democratization)」的核心理念為何？",
      "options": [
        { "key": "A", "value": "將 AI 系統完全開源，供任何企業免費進行商業販售" },
        { "key": "B", "value": "利用 AI 取代各國傳統的投票系統" },
        { "key": "C", "value": "透過降低技術門檻，讓非技術背景人士與中小企業也能參與 AI 開發並受益" },
        { "key": "D", "value": "限制大型科技公司研發 AI，將資源強制分配給新創企業" }
      ],
      "answer": "C",
      "explanation": "AI 民主化旨在降低 AI 的技術門檻，將 AI 的使用擴展到更廣泛的社會層面，讓更多非技術背景的人士和中小型企業都能夠參與 AI 開發並受益 [1]。",
      "score": 2,
      "tags": ["AI民主化", "核心理念"]
    },
    {
      "id": "q3",
      "type": "single_choice",
      "questionText": "在評估導入 No Code / Low Code 平台時，企業必須衡量該平台的「總擁有成本 (Total Cost of Ownership, TCO)」。下列何者屬於 TCO 的評估範疇？",
      "options": [
        { "key": "A", "value": "包含平台的購買、長期維護、員工培訓等直接與隱性相關成本" },
        { "key": "B", "value": "僅包含軟體的初始購買授權費用" },
        { "key": "C", "value": "僅計算硬體設備的採購費用" },
        { "key": "D", "value": "平台幫助企業提升的總營收" }
      ],
      "answer": "A",
      "explanation": "總擁有成本 (TCO) 考量的不僅是初期的購買費用，還必須包含後續的維護、系統整合、員工培訓等相關成本與隱性費用 [1]。",
      "score": 2,
      "tags": ["導入評估", "TCO"]
    },
    {
      "id": "q4",
      "type": "single_choice",
      "questionText": "在文本數據進入深度學習模型訓練前，必須先將文本拆分為基本單元（例如詞或子詞），以便模型處理。這個關鍵步驟稱為？",
      "options": [
        { "key": "A", "value": "向量化表示 (Vectorization)" },
        { "key": "B", "value": "標記化處理 (Tokenization)" },
        { "key": "C", "value": "數據清洗 (Data Cleaning)" },
        { "key": "D", "value": "交叉驗證 (Cross Validation)" }
      ],
      "answer": "B",
      "explanation": "標記化處理 (Tokenization) 是將文本數據拆分為基本單元（如詞或子詞），這是讓語言模型能夠處理與理解文本的重要前置步驟 [1]。",
      "score": 2,
      "tags": ["技術概念", "Tokenization"]
    },
    {
      "id": "q5",
      "type": "single_choice",
      "questionText": "在使用生成式 AI 進行推理（Inference）時，哪一個參數主要用來控制生成內容的「隨機性」與「創造力」，數值越高生成的內容越具創意？",
      "options": [
        { "key": "A", "value": "學習率 (Learning Rate)" },
        { "key": "B", "value": "丟棄率 (Dropout Rate)" },
        { "key": "C", "value": "溫度參數 (Temperature Parameter)" },
        { "key": "D", "value": "批次大小 (Batch Size)" }
      ],
      "answer": "C",
      "explanation": "溫度參數 (Temperature Parameter) 用於控制生成內容的隨機性。低溫度值會生成較保守、確定的內容，高溫度值則生成更具創意與多樣性的內容 [1]。",
      "score": 2,
      "tags": ["推理機制", "溫度參數"]
    },
    {
      "id": "q6",
      "type": "single_choice",
      "questionText": "在生成式模型的採樣機制中，「選擇累積機率達到某一閾值（如 0.9）的選項進行採樣」，以更靈活地平衡內容品質與隨機性。此機制稱為？",
      "options": [
        { "key": "A", "value": "核採樣 (Nucleus Sampling / Top-p)" },
        { "key": "B", "value": "頂部採樣 (Top-k Sampling)" },
        { "key": "C", "value": "貪婪搜索 (Greedy Search)" },
        { "key": "D", "value": "波束搜索 (Beam Search)" }
      ],
      "answer": "A",
      "explanation": "核採樣 (Nucleus Sampling) 是選擇累積機率達到某一閾值（如 0.9）的選項進行採樣，動態調整候選詞數量，靈活平衡品質與隨機性 [1]。",
      "score": 2,
      "tags": ["推理機制", "核採樣"]
    },
    {
      "id": "q7",
      "type": "single_choice",
      "questionText": "在大型語言模型 (LLM) 的技術架構中，哪一種機制使其能夠有效處理長距離的依賴關係，並學習序列數據的內在結構？",
      "options": [
        { "key": "A", "value": "池化層 (Pooling Layer)" },
        { "key": "B", "value": "自注意力機制 (Self-Attention)" },
        { "key": "C", "value": "卷積運算 (Convolution)" },
        { "key": "D", "value": "核函數映射 (Kernel Trick)" }
      ],
      "answer": "B",
      "explanation": "Transformer 架構中的注意力機制，特別是「自注意力 (Self-Attention)」，有助於處理長距離依賴關係，並有效學習序列數據的內在結構 [1]。",
      "score": 2,
      "tags": ["技術概念", "注意力機制"]
    },
    {
      "id": "q8",
      "type": "single_choice",
      "questionText": "廣泛應用於 Midjourney 等工具，透過「逐步向數據添加高斯雜訊，再透過神經網路反向去除雜訊」來重建高畫質圖像的生成模型為？",
      "options": [
        { "key": "A", "value": "變分自編碼器 (VAE)" },
        { "key": "B", "value": "生成對抗網路 (GAN)" },
        { "key": "C", "value": "擴散模型 (Diffusion Models)" },
        { "key": "D", "value": "自迴歸模型 (Autoregressive Models)" }
      ],
      "answer": "C",
      "explanation": "擴散模型 (Diffusion Models) 的技術核心是透過逐步添加雜訊及反向去噪的過程來重建影像，在圖像生成應用中展現極高的準確性與自然感 [1]。",
      "score": 2,
      "tags": ["生成式AI", "擴散模型"]
    },
    {
      "id": "q9",
      "type": "single_choice",
      "questionText": "企業無需建置高階硬體，即可透過雲端平台訂閱或 API 呼叫，存取高效能的生成式 AI 工具。這種商業模式稱為什麼？",
      "options": [
        { "key": "A", "value": "IaaS (基礎設施即服務)" },
        { "key": "B", "value": "AIaaS (AI 即服務)" },
        { "key": "C", "value": "在地化部署 (On-premise)" },
        { "key": "D", "value": "邊緣運算 (Edge Computing)" }
      ],
      "answer": "B",
      "explanation": "AI 即服務 (AIaaS) 透過雲端平台提供 API 服務，讓用戶無需具備高階硬體或專業知識，即可輕鬆存取並整合高效能的 AI 工具 [1]。",
      "score": 2,
      "tags": ["商業模式", "AIaaS"]
    },
    {
      "id": "q10",
      "type": "single_choice",
      "questionText": "在深度學習模型微調（Fine-tuning）的過程中，若模型過度適應新的特定領域資料，導致逐漸遺忘先前預訓練所獲得的廣泛知識，這種現象稱為？",
      "options": [
        { "key": "A", "value": "梯度爆炸 (Gradient Explosion)" },
        { "key": "B", "value": "模式崩潰 (Mode Collapse)" },
        { "key": "C", "value": "災難性遺忘 (Catastrophic Forgetting)" },
        { "key": "D", "value": "欠擬合 (Underfitting)" }
      ],
      "answer": "C",
      "explanation": "災難性遺忘是指神經網路在學習新任務（微調）時，覆蓋了舊任務的權重配置，導致原本具備的廣泛知識與通用表現大幅下降 [1]。",
      "score": 2,
      "tags": ["模型微調", "災難性遺忘"]
    },
    {
      "id": "q11",
      "type": "single_choice",
      "questionText": "為了使生成結果更貼近人類偏好與需求，許多大型語言模型在訓練後期會引入哪一種結合人類審查的強化學習技術？",
      "options": [
        { "key": "A", "value": "人類回饋強化學習 (RLHF)" },
        { "key": "B", "value": "無監督聚類 (Unsupervised Clustering)" },
        { "key": "C", "value": "主成分分析 (PCA)" },
        { "key": "D", "value": "聯邦學習 (Federated Learning)" }
      ],
      "answer": "A",
      "explanation": "人類回饋強化學習 (RLHF) 讓模型能根據人類的評價與偏好進行優化，使生成結果更安全、貼近用戶需求 [1]。",
      "score": 2,
      "tags": ["技術概念", "RLHF"]
    },
    {
      "id": "q12",
      "type": "single_choice",
      "questionText": "企業為了在資源有限的邊緣設備（如手機）上運行生成式 AI，常透過移除神經網路中不重要或冗餘的權重來簡化模型。這項技術稱為？",
      "options": [
        { "key": "A", "value": "模型剪枝 (Model Pruning)" },
        { "key": "B", "value": "數據增強 (Data Augmentation)" },
        { "key": "C", "value": "提示工程 (Prompt Engineering)" },
        { "key": "D", "value": "交叉驗證 (Cross Validation)" }
      ],
      "answer": "A",
      "explanation": "模型剪枝 (Pruning) 透過移除神經網路中影響較小的冗餘權重或連接，來簡化模型結構，達到壓縮模型並加速推論速度的目的 [1]。",
      "score": 2,
      "tags": ["模型優化", "模型剪枝"]
    },
    {
      "id": "q13",
      "type": "single_choice",
      "questionText": "生成式 AI 應用於「醫療保健」領域時，下列哪一項是其典型的應用場景？",
      "options": [
        { "key": "A", "value": "預測潛在藥物分子結構以縮短研發週期" },
        { "key": "B", "value": "自動生成高頻交易演算法" },
        { "key": "C", "value": "優化製造業的供應鏈與庫存成本" },
        { "key": "D", "value": "生成遊戲中的 3D 動畫場景" }
      ],
      "answer": "A",
      "explanation": "在醫療領域，生成式 AI 可分析大量生物醫學數據，預測分子結構，協助新藥開發與設計，從而縮短研發週期 [1]。",
      "score": 2,
      "tags": ["產業應用", "醫療保健"]
    },
    {
      "id": "q14",
      "type": "single_choice",
      "questionText": "在金融業中，生成式 AI 最具代表性的應用之一為何？",
      "options": [
        { "key": "A", "value": "模擬市場情境進行風險評估與投資組合優化" },
        { "key": "B", "value": "生成產品設計的 3D 原型" },
        { "key": "C", "value": "撰寫並生成電子病歷" },
        { "key": "D", "value": "優化工廠的自動化生產線" }
      ],
      "answer": "A",
      "explanation": "金融業中，生成式 AI 可模擬各種市場情境協助風險評估，並結合市場數據提供最佳投資組合建議及自動化合規監管 [1]。",
      "score": 2,
      "tags": ["產業應用", "金融業"]
    },
    {
      "id": "q15",
      "type": "single_choice",
      "questionText": "企業導入生成式 AI 時，若缺乏明確策略，容易造成資源浪費。導入規劃的第一個階段通常是？",
      "options": [
        { "key": "A", "value": "購買硬體並立即上線服務" },
        { "key": "B", "value": "全面裁撤非技術人員" },
        { "key": "C", "value": "明確經營目標、識別痛點並評估現狀" },
        { "key": "D", "value": "將所有內部數據上傳至公共雲端" }
      ],
      "answer": "C",
      "explanation": "企業導入 AI 的準備階段應首先明確經營目標與核心價值，深入分析現有營運模式，並識別痛點，以設計具體可行的應用策略 [1]。",
      "score": 2,
      "tags": ["導入規劃", "需求評估"]
    },
    {
      "id": "q16",
      "type": "single_choice",
      "questionText": "企業評估生成式 AI 專案的財務可行性時，為納入現金流時間分佈的考量，常計算下列哪兩項財務指標？",
      "options": [
        { "key": "A", "value": "淨現值 (NPV) 與 內部報酬率 (IRR)" },
        { "key": "B", "value": "精確率 (Precision) 與 召回率 (Recall)" },
        { "key": "C", "value": "BLEU 與 ROUGE" },
        { "key": "D", "value": "GPU 使用率 與 延遲 (Latency)" }
      ],
      "answer": "A",
      "explanation": "計算 ROI 時，會使用回本時間預估模型並納入現金流分析，計算淨現值（NPV）與內部報酬率（IRR），以評估方案的財務可行性與長期收益潛力 [1]。",
      "score": 2,
      "tags": ["導入評估", "ROI計算"]
    },
    {
      "id": "q17",
      "type": "single_choice",
      "questionText": "在 AI 導入計畫中，透過「敏感性分析 (Sensitivity Analysis)」可以幫助企業達到什麼目的？",
      "options": [
        { "key": "A", "value": "模擬不同市場條件或成本變動對方案收益的影響，識別風險與機會" },
        { "key": "B", "value": "尋找訓練資料中的敏感個資並加密" },
        { "key": "C", "value": "分析員工對新 AI 工具的抗拒心理" },
        { "key": "D", "value": "測試模型對微小雜訊擾動的抗干擾能力" }
      ],
      "answer": "A",
      "explanation": "在財務與效益評估中，敏感性分析能有效模擬市場條件、業務情境或成本變動對方案收益的影響，幫助企業制定靈活的投資策略 [1]。",
      "score": 2,
      "tags": ["導入評估", "敏感性分析"]
    },
    {
      "id": "q18",
      "type": "single_choice",
      "questionText": "在大型語言模型（LLM）的訓練過程中，哪一種損失函數（Loss Function）最常被用於評估生成詞語的預測誤差？",
      "options": [
        { "key": "A", "value": "交叉熵損失 (Cross-Entropy Loss)" },
        { "key": "B", "value": "均方誤差 (MSE)" },
        { "key": "C", "value": "平滑 L1 損失 (Smooth L1 Loss)" },
        { "key": "D", "value": "餘弦相似度 (Cosine Similarity)" }
      ],
      "answer": "A",
      "explanation": "在自迴歸模型的訓練中，最常用的損失函數為交叉熵損失（Cross-Entropy Loss），它能有效衡量模型預測下一個詞語的機率分佈與真實標籤之間的差異 [1]。",
      "score": 2,
      "tags": ["模型訓練", "損失函數"]
    },
    {
      "id": "q19",
      "type": "single_choice",
      "questionText": "在生成式 AI 大型模型的訓練中，採用「混合精度訓練 (Mixed Precision Training)」的主要目的為何？",
      "options": [
        { "key": "A", "value": "減少計算資源的消耗並加速訓練速度，同時不影響最終精度" },
        { "key": "B", "value": "強制移除數據集中的所有偏見資訊" },
        { "key": "C", "value": "提高生成影像的對比度與色彩飽和度" },
        { "key": "D", "value": "完全解決模型的 AI 幻覺問題" }
      ],
      "answer": "A",
      "explanation": "混合精度訓練有助於在不影響模型最終精度的前提下，大幅減少記憶體與計算資源的消耗，並加速模型的訓練速度 [1]。",
      "score": 2,
      "tags": ["模型訓練", "混合精度訓練"]
    },
    {
      "id": "q20",
      "type": "single_choice",
      "questionText": "在驗證生成式語言模型的效能時，常用來評估模型生成文本品質與語言流暢性的量化標準指標為何？",
      "options": [
        { "key": "A", "value": "BLEU、ROUGE、Perplexity" },
        { "key": "B", "value": "GDPR、CCPA" },
        { "key": "C", "value": "NPV、IRR" },
        { "key": "D", "value": "SVM、KNN、K-Means" }
      ],
      "answer": "A",
      "explanation": "評估生成式 AI 語言模型效能時，常採用 BLEU、ROUGE、Perplexity 等量化標準，以客觀衡量生成內容的相似度、品質與流暢性 [1]。",
      "score": 2,
      "tags": ["模型評估", "量化指標"]
    },
    {
      "id": "q21",
      "type": "single_choice",
      "questionText": "在 AI 專案導入初期，企業通常會進行小範圍的「概念驗證 (POC) 試點」。此階段最關鍵的目標為何？",
      "options": [
        { "key": "A", "value": "在真實業務場景中驗證技術效果，收集回饋以調整後續全面推廣計畫" },
        { "key": "B", "value": "一次性取代現有的所有核心系統" },
        { "key": "C", "value": "裁減不需要的非技術員工以節省成本" },
        { "key": "D", "value": "公開發布測試版本讓全球用戶公測" }
      ],
      "answer": "A",
      "explanation": "試點（POC）階段的核心目標在於透過低成本且風險可控的方式，驗證 AI 技術在真實業務場景中的可行性與效果，並累積經驗作為擴大推廣的基礎 [1]。",
      "score": 2,
      "tags": ["導入規劃", "POC"]
    },
    {
      "id": "q22",
      "type": "single_choice",
      "questionText": "模型上線後，若因為業務場景或用戶行為隨時間改變，導致「輸入數據的分佈特徵」發生改變，使模型預測準確性下降。這種現象稱為？",
      "options": [
        { "key": "A", "value": "數據漂移 (Data Drift)" },
        { "key": "B", "value": "災難性遺忘 (Catastrophic Forgetting)" },
        { "key": "C", "value": "梯度消失 (Vanishing Gradient)" },
        { "key": "D", "value": "模式崩潰 (Mode Collapse)" }
      ],
      "answer": "A",
      "explanation": "數據漂移（Data Drift）是指隨著時間推移，輸入數據的分佈發生變化，導致模型效能下降。企業需定期檢查並執行自動化重新訓練來應對 [1]。",
      "score": 2,
      "tags": ["營運管理", "數據漂移"]
    },
    {
      "id": "q23",
      "type": "single_choice",
      "questionText": "生成式 AI 可能「一本正經地胡說八道」，生成虛構或不存在的資訊。此種挑戰被廣泛稱為什麼？",
      "options": [
        { "key": "A", "value": "AI 幻覺 (AI Hallucinations)" },
        { "key": "B", "value": "數據漂移 (Data Drift)" },
        { "key": "C", "value": "對抗性攻擊 (Adversarial Attack)" },
        { "key": "D", "value": "反向工程 (Reverse Engineering)" }
      ],
      "answer": "A",
      "explanation": "AI 幻覺 (AI Hallucinations) 是指模型生成看似合理但實際上不準確、虛構或毫無根據的內容，嚴重影響內容的真實性與可靠性 [1]。",
      "score": 2,
      "tags": ["風險管理", "AI幻覺"]
    },
    {
      "id": "q24",
      "type": "single_choice",
      "questionText": "在 AI 的風險評估中，實務上常使用「風險矩陣 (Risk Matrix)」。此工具主要是將哪兩個維度進行交叉對比，以判定風險優先級別？",
      "options": [
        { "key": "A", "value": "發生概率 與 影響程度" },
        { "key": "B", "value": "開發成本 與 預期收益" },
        { "key": "C", "value": "模型參數大小 與 訓練時間" },
        { "key": "D", "value": "硬體算力 與 儲存空間" }
      ],
      "answer": "A",
      "explanation": "風險矩陣將風險的「發生概率」與其「影響程度」進行交叉對比，幫助決策者直觀了解各類風險的權重，優先處理高風險問題 [1]。",
      "score": 2,
      "tags": ["風險評估", "風險矩陣"]
    },
    {
      "id": "q25",
      "type": "single_choice",
      "questionText": "若企業評估某一 AI 應用的技術尚未成熟或可能導致重大損害，決定暫緩開發該專案。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險迴避 (Risk Avoidance)" },
        { "key": "B", "value": "風險轉移 (Risk Transfer)" },
        { "key": "C", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "D", "value": "風險接受 (Risk Acceptance)" }
      ],
      "answer": "A",
      "explanation": "風險迴避適用於技術不成熟或可能導致重大損害的場景。企業透過暫緩開發或停止高風險應用，完全避免該風險的發生 [1]。",
      "score": 2,
      "tags": ["風險管理", "風險迴避"]
    },
    {
      "id": "q26",
      "type": "single_choice",
      "questionText": "企業透過購買保險或與外部雲端服務商簽署合約，將 AI 系統運營的潛在資安責任交由第三方承擔。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險轉移 (Risk Transfer)" },
        { "key": "B", "value": "風險迴避 (Risk Avoidance)" },
        { "key": "C", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "D", "value": "風險接受 (Risk Acceptance)" }
      ],
      "answer": "A",
      "explanation": "風險轉移是透過購買保險或與外部合作夥伴簽署協議（外包），將部分或全部的風險責任轉移給第三方 [1]。",
      "score": 2,
      "tags": ["風險管理", "風險轉移"]
    },
    {
      "id": "q27",
      "type": "single_choice",
      "questionText": "針對生成內容可能包含的不當訊息，企業制定明確政策並設置嚴格的「內容審查與過濾機制」，以降低風險發生的機率或減輕其影響。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "B", "value": "風險接受 (Risk Acceptance)" },
        { "key": "C", "value": "風險迴避 (Risk Avoidance)" },
        { "key": "D", "value": "風險轉移 (Risk Transfer)" }
      ],
      "answer": "A",
      "explanation": "風險緩解是透過設置安全控制措施（如內容過濾與人工審查），以降低潛在風險發生的機率或減輕其造成的負面影響 [1]。",
      "score": 2,
      "tags": ["風險管理", "風險緩解"]
    },
    {
      "id": "q28",
      "type": "single_choice",
      "questionText": "在 AI 風險管理中，「風險接受 (Risk Acceptance)」策略通常適用於何種情況？",
      "options": [
        { "key": "A", "value": "風險的影響有限或無法完全避免，企業評估在其容忍度內並準備了應急計畫" },
        { "key": "B", "value": "風險的影響極大且發生機率極高" },
        { "key": "C", "value": "企業完全沒有預算進行任何防護" },
        { "key": "D", "value": "法規嚴格禁止的違規操作" }
      ],
      "answer": "A",
      "explanation": "風險接受適用於風險影響有限或無法完全避免的情況。企業基於現實條件與容忍度，選擇接受風險並制定詳細的應急準備方案以平衡效益 [1]。",
      "score": 2,
      "tags": ["風險管理", "風險接受"]
    },
    {
      "id": "q29",
      "type": "single_choice",
      "questionText": "為了解決生成式 AI 決策過程如同「黑箱 (Black Box)」的問題，企業在進行風險溯源時，應引入哪一項技術以確保生成內容和過程具備可追溯性？",
      "options": [
        { "key": "A", "value": "可解釋性 AI 技術 (Explainable AI, XAI)" },
        { "key": "B", "value": "卷積神經網路 (CNN)" },
        { "key": "C", "value": "批次正規化 (Batch Normalization)" },
        { "key": "D", "value": "自動編碼器 (Autoencoder)" }
      ],
      "answer": "A",
      "explanation": "可解釋性 AI (XAI) 技術能確保模型生成過程的透明化，讓數據輸入、處理邏輯與模型參數的運行情況具備可追溯性，增強結果的可信度 [1]。",
      "score": 2,
      "tags": ["風險管理", "風險溯源"]
    },
    {
      "id": "q30",
      "type": "single_choice",
      "questionText": "惡意使用者可能透過精心設計的輸入指令（如越獄提示詞 Prompt Injection），試圖操控模型輸出或誘導模型洩露隱私訊息。此種安全風險被稱為？",
      "options": [
        { "key": "A", "value": "對抗性攻擊 (Adversarial Attack)" },
        { "key": "B", "value": "數據漂移 (Data Drift)" },
        { "key": "C", "value": "災難性遺忘 (Catastrophic Forgetting)" },
        { "key": "D", "value": "模式崩潰 (Mode Collapse)" }
      ],
      "answer": "A",
      "explanation": "對抗性攻擊包含透過精心設計的輸入（如提示詞攻擊）來操控模型的行為，誘導其生成不當內容或洩露訓練數據中的機密資訊 [1]。",
      "score": 2,
      "tags": ["風險管理", "對抗性攻擊"]
    },
    {
      "id": "q31",
      "type": "single_choice",
      "questionText": "為了降低模型訓練資料中的敏感個資外洩風險，企業可採用哪一種技術，為數據添加雜訊，在保證整體數據分析有效性的同時保護個人隱私？",
      "options": [
        { "key": "A", "value": "差分隱私技術 (Differential Privacy)" },
        { "key": "B", "value": "聯邦學習 (Federated Learning)" },
        { "key": "C", "value": "A/B 測試 (A/B Testing)" },
        { "key": "D", "value": "模型量化 (Model Quantization)" }
      ],
      "answer": "A",
      "explanation": "差分隱私（Differential Privacy）技術透過在數據中加入適度雜訊，能防止攻擊者推斷出特定個人的敏感資訊，是資料隱私保護的關鍵技術 [1]。",
      "score": 2,
      "tags": ["風險管理", "差分隱私"]
    },
    {
      "id": "q32",
      "type": "single_choice",
      "questionText": "為了降低模型在特定族群（如性別、種族）上產生不公平預測或生成內容偏見，在準備訓練資料時，最重要的應對措施為何？",
      "options": [
        { "key": "A", "value": "確保訓練數據具備多樣性與代表性，並使用去偏見技術" },
        { "key": "B", "value": "盡可能增加模型的神經網路層數" },
        { "key": "C", "value": "僅使用單一國家的資料進行訓練以保證一致性" },
        { "key": "D", "value": "將所有與人類屬性相關的特徵刪除" }
      ],
      "answer": "A",
      "explanation": "模型偏見多源自訓練資料的不平衡。確保訓練數據的多樣性，並在過程中採用去偏見技術與公平性測試，是降低倫理偏見最直接有效的方法 [1]。",
      "score": 2,
      "tags": ["AI倫理", "偏見防範"]
    },
    {
      "id": "q33",
      "type": "single_choice",
      "questionText": "將文字、圖像、音訊等多種資料格式結合，例如給定一段文字即可生成對應的圖片或影片（如 DALL-E），這類生成式 AI 技術稱為什麼？",
      "options": [
        { "key": "A", "value": "多模態生成 (Multi-modal Generation)" },
        { "key": "B", "value": "單模態生成 (Uni-modal Generation)" },
        { "key": "C", "value": "強化學習生成 (RL-based Generation)" },
        { "key": "D", "value": "聯邦式生成 (Federated Generation)" }
      ],
      "answer": "A",
      "explanation": "多模態生成 (Multi-modal) 是指將文本、圖像、音訊等多種模態結合的技術，例如 DALL-E 將文本描述轉化為圖像，開創了更豐富的應用場景 [1]。",
      "score": 2,
      "tags": ["生成式AI", "多模態"]
    },
    {
      "id": "q34",
      "type": "single_choice",
      "questionText": "企業導入生成式 AI 的準備階段中，除了設立明確目標與選定應用範圍外，還必須進行「提取改善項目」。此步驟的核心動作為何？",
      "options": [
        { "key": "A", "value": "繪製業務流程圖並找出重複性、規則性高的工作，作為優先導入候選" },
        { "key": "B", "value": "直接購買市面上最昂貴的 AI 軟體" },
        { "key": "C", "value": "裁撤所有涉及該流程的員工" },
        { "key": "D", "value": "停止所有現有業務，直到 AI 開發完成" }
      ],
      "answer": "A",
      "explanation": "在準備階段，應詳細繪製各部門的業務流程圖，從中找出具有重複性、規則性和標準化的工作（如數據處理、報表生成），這些是理想的 AI 改善項目 [1]。",
      "score": 2,
      "tags": ["導入規劃", "需求評估"]
    },
    {
      "id": "q35",
      "type": "single_choice",
      "questionText": "生成式 AI 在驗證效能時，為確認模型在「實際應用中的表現與適應能力」，通常會建立哪一種驗證機制來確保使用者滿意度？",
      "options": [
        { "key": "A", "value": "主觀人工檢查（結合專家與用戶回饋）" },
        { "key": "B", "value": "隨機刪除程式碼" },
        { "key": "C", "value": "硬體過熱測試" },
        { "key": "D", "value": "單純依靠 BLEU 指標的自動評分" }
      ],
      "answer": "A",
      "explanation": "除了自動化的量化指標外，主觀人工檢查（結合領域專家評估與最終用戶回饋）對於檢驗生成內容的創意、滿意度與實際適用性至關重要 [1]。",
      "score": 2,
      "tags": ["效能驗證", "人工檢查"]
    },
    {
      "id": "q36",
      "type": "single_choice",
      "questionText": "No Code 平台的設計初衷，主要針對哪一類型的工作場景與人員？",
      "options": [
        { "key": "A", "value": "適合非技術背景者用於快速原型設計或解決簡單業務問題" },
        { "key": "B", "value": "針對需要編寫底層作業系統的專業工程師" },
        { "key": "C", "value": "專門用於訓練具有千億參數的大型語言模型" },
        { "key": "D", "value": "僅能用於硬體設備的韌體開發" }
      ],
      "answer": "A",
      "explanation": "No Code 平台透過視覺化介面和拖放操作，讓使用者無需編寫程式碼即可開發應用，特別適合非技術背景者進行快速原型設計或建立內部簡單工具 [1]。",
      "score": 2,
      "tags": ["No code / Low code", "適用場景"]
    },
    {
      "id": "q37",
      "type": "single_choice",
      "questionText": "與 No Code 平台相比，Low Code 平台具備什麼樣的獨特優勢，使其更適合中大型企業？",
      "options": [
        { "key": "A", "value": "允許編寫少量程式碼以實現深度整合、高度客製化與複雜邏輯" },
        { "key": "B", "value": "完全不需要任何程式設計基礎" },
        { "key": "C", "value": "僅能建立靜態的文字網頁" },
        { "key": "D", "value": "不支援與任何外部 API 的連接" }
      ],
      "answer": "A",
      "explanation": "Low Code 平台結合了視覺化開發工具與程式碼擴充功能，允許技術人員編寫少量程式碼，能滿足中大型企業對於複雜邏輯與系統深度整合的需求 [1]。",
      "score": 2,
      "tags": ["No code / Low code", "Low Code優勢"]
    },
    {
      "id": "q38",
      "type": "single_choice",
      "questionText": "生成式 AI 在教育領域的應用可以顯著減輕教師負擔並提升學習體驗。下列何者為典型的教育應用？",
      "options": [
        { "key": "A", "value": "自動化教材生成與提供即時互動的智慧教學助理" },
        { "key": "B", "value": "自動預測股市漲跌" },
        { "key": "C", "value": "執行外科手術模擬的實際操作" },
        { "key": "D", "value": "撰寫並發布政府公文" }
      ],
      "answer": "A",
      "explanation": "在教育領域，生成式 AI 可自動創建教學材料、設計個人化學習路徑，並作為智慧教學助理即時回應學生問題，顯著優化教育體驗 [1]。",
      "score": 2,
      "tags": ["產業應用", "教育"]
    },
    {
      "id": "q39",
      "type": "single_choice",
      "questionText": "在生成式 AI 的「人機協作機制 (Human-in-the-loop)」中，人類專家的主要職責通常包含下列何者？",
      "options": [
        { "key": "A", "value": "強化內容生成的審核與優化，並在關鍵場景設置人工干預以降低風險" },
        { "key": "B", "value": "手動輸入百億個訓練數據參數" },
        { "key": "C", "value": "負責硬體伺服器的實體組裝" },
        { "key": "D", "value": "直接撰寫機器學習的底層 C++ 演算法" }
      ],
      "answer": "A",
      "explanation": "人機協作機制的目的是結合人類的專業知識與 AI 效率，透過人類審核與人工干預，確保生成內容的準確性、合規性與安全性 [1]。",
      "score": 2,
      "tags": ["風險管理", "人機協作"]
    },
    {
      "id": "q40",
      "type": "single_choice",
      "questionText": "下列何者「不是」No Code / Low Code 平台的主要優勢？",
      "options": [
        { "key": "A", "value": "完全取代所有專業軟體工程師的工作" },
        { "key": "B", "value": "降低企業開發成本" },
        { "key": "C", "value": "縮短應用程式的上市時間" },
        { "key": "D", "value": "幫助非技術人員快速建立原型" }
      ],
      "answer": "A",
      "explanation": "No Code / Low Code 平台能大幅降低對技術人員的依賴並加速開發，但無法「完全取代」專業軟體工程師，特別是在需要處理底層架構、高複雜邏輯與特殊客製化需求時 [1]。",
      "score": 2,
      "tags": ["No code / Low code", "限制"]
    },
    {
      "id": "q41",
      "type": "single_choice",
      "questionText": "某企業欲利用現有開源的大型語言模型，針對其專屬的客服對話紀錄進行訓練，使模型更符合其特定業務的語氣與專業知識。此優化過程稱為？",
      "options": [
        { "key": "A", "value": "模型微調 (Fine-tuning)" },
        { "key": "B", "value": "預訓練 (Pre-training)" },
        { "key": "C", "value": "模型量化 (Quantization)" },
        { "key": "D", "value": "資料清洗 (Data Cleaning)" }
      ],
      "answer": "A",
      "explanation": "利用預訓練模型，針對特定領域或任務的資料（如企業專屬客服對話）進行進一步的訓練調整，以提升專門任務效能，這稱為模型微調 (Fine-tuning) [1]。",
      "score": 2,
      "tags": ["技術概念", "微調"]
    },
    {
      "id": "q42",
      "type": "single_choice",
      "questionText": "在 AI 的運營與監控中，為了在模型效能達到警戒值時自動觸發更新過程，並將新模型部署至生產環境，企業應建構什麼系統？",
      "options": [
        { "key": "A", "value": "自動化重新訓練管道 (Retraining Pipeline)" },
        { "key": "B", "value": "分散式拒絕服務攻擊防禦 (DDoS Protection)" },
        { "key": "C", "value": "虛擬實境 (VR) 介面" },
        { "key": "D", "value": "硬體散熱系統" }
      ],
      "answer": "A",
      "explanation": "自動化的重新訓練管道 (Retraining Pipeline) 可以在監控到效能下降（如數據漂移）時，自動觸發訓練並部署更新後的模型，減少人工干預與時間成本 [1]。",
      "score": 2,
      "tags": ["營運管理", "自動化管道"]
    },
    {
      "id": "q43",
      "type": "single_choice",
      "questionText": "「變分自編碼器 (VAE)」在生成式 AI 中被廣泛應用。它的基本架構主要包含哪兩個核心部分來完成從壓縮到重建的過程？",
      "options": [
        { "key": "A", "value": "編碼器 (Encoder) 與 解碼器 (Decoder)" },
        { "key": "B", "value": "生成器 (Generator) 與 鑑別器 (Discriminator)" },
        { "key": "C", "value": "演員 (Actor) 與 評論家 (Critic)" },
        { "key": "D", "value": "卷積層 (Conv Layer) 與 池化層 (Pooling Layer)" }
      ],
      "answer": "A",
      "explanation": "VAE 的架構包含編碼器與解碼器。編碼器負責將輸入資料壓縮並映射到潛在空間的分佈，解碼器則從該空間採樣並重建出原始資料 [1]。",
      "score": 2,
      "tags": ["生成式AI", "VAE"]
    },
    {
      "id": "q44",
      "type": "single_choice",
      "questionText": "神經網路在訓練過程中，為提升模型收斂速度並根據不同的參數規模自動調整學習步長，實務上對於大型語言模型最常選用的優化器 (Optimizer) 為？",
      "options": [
        { "key": "A", "value": "AdamW 或 LAMB" },
        { "key": "B", "value": "SVM" },
        { "key": "C", "value": "K-Means" },
        { "key": "D", "value": "決策樹" }
      ],
      "answer": "A",
      "explanation": "AdamW 和 LAMB 是深度學習（特別是大型語言模型）中常用的優化器，它們能針對不同模型大小自適應調整學習率，控制收斂的穩定性與效率 [1]。",
      "score": 2,
      "tags": ["模型訓練", "優化器"]
    },
    {
      "id": "q45",
      "type": "single_choice",
      "questionText": "在企業內部建立「風險文化」的過程中，下列哪一項做法能有效強化基層員工對 AI 風險的參與與警覺性？",
      "options": [
        { "key": "A", "value": "建立風險報告機制與獎勵政策，鼓勵主動報告風險並提出改進建議" },
        { "key": "B", "value": "禁止基層員工討論 AI 相關話題" },
        { "key": "C", "value": "將所有風險管理責任完全推給外部供應商" },
        { "key": "D", "value": "僅由高階主管負責所有風險稽核" }
      ],
      "answer": "A",
      "explanation": "風險文化強調全體參與。透過培訓、案例分析以及建立風險報告與獎勵機制，可以鼓勵員工主動識別與報告潛在的 AI 風險 [1]。",
      "score": 2,
      "tags": ["風險管理", "風險文化"]
    },
    {
      "id": "q46",
      "type": "single_choice",
      "questionText": "在評估生成式 AI 的應用風險時，下列哪兩項隱私保護法規是企業在全球營運時最常需要遵循的標準？",
      "options": [
        { "key": "A", "value": "GDPR 與 CCPA" },
        { "key": "B", "value": "IFRS 與 GAAP" },
        { "key": "C", "value": "ISO 9001 與 ISO 14001" },
        { "key": "D", "value": "Basel III 與 SOX" }
      ],
      "answer": "A",
      "explanation": "生成式 AI 在處理個人資料時，必須符合現行的資料隱私保護規範，其中最具代表性的即為歐盟的《一般資料保護規則》(GDPR) 與美國加州的 CCPA [1]。",
      "score": 2,
      "tags": ["法規遵循", "隱私保護"]
    },
    {
      "id": "q47",
      "type": "single_choice",
      "questionText": "「生成對抗網路 (GAN)」是高品質圖像生成的代表技術。其透過哪兩個網路的相互博弈來提升生成內容的真實感？",
      "options": [
        { "key": "A", "value": "生成器與鑑別器" },
        { "key": "B", "value": "編碼器與解碼器" },
        { "key": "C", "value": "輸入層與輸出層" },
        { "key": "D", "value": "自注意力與交叉注意力" }
      ],
      "answer": "A",
      "explanation": "GAN 包含生成器（負責製造假資料）與鑑別器（負責分辨真假資料），兩者在訓練過程中互相對抗，最終使生成器產出極具真實感的數據 [1]。",
      "score": 2,
      "tags": ["生成式AI", "GAN"]
    },
    {
      "id": "q48",
      "type": "single_choice",
      "questionText": "為了防止大型神經網路在訓練過程中發生「過擬合 (Overfitting)」，實務上經常採用的正則化技術包括 L2 正則化以及哪一項機制？",
      "options": [
        { "key": "A", "value": "Dropout (隨機丟棄神經元)" },
        { "key": "B", "value": "核採樣 (Nucleus Sampling)" },
        { "key": "C", "value": "網格搜索 (Grid Search)" },
        { "key": "D", "value": "自注意力機制 (Self-Attention)" }
      ],
      "answer": "A",
      "explanation": "Dropout 是一種強大的正則化技術，透過在訓練時隨機關閉部分神經元，強迫模型學習更穩健的特徵，有效防止過擬合 [1]。",
      "score": 2,
      "tags": ["模型訓練", "正則化"]
    },
    {
      "id": "q49",
      "type": "single_choice",
      "questionText": "在評估生成式 AI 導入方案時，系統架構需具備「系統可擴展性」。這代表什麼意義？",
      "options": [
        { "key": "A", "value": "架構需具備彈性，能隨著應用規模與數據量的增加進行擴展與調整" },
        { "key": "B", "value": "系統能支援無限多種程式語言" },
        { "key": "C", "value": "軟體能自動將錯誤代碼隱藏" },
        { "key": "D", "value": "企業不需要再購買任何硬體" }
      ],
      "answer": "A",
      "explanation": "系統可擴展性（Scalability）指的是基礎架構（如伺服器、雲端空間）必須具備足夠的彈性，當 AI 應用的需求或數據規模成長時，系統能夠順利擴展以維持穩定運行 [1]。",
      "score": 2,
      "tags": ["導入評估", "系統可擴展性"]
    },
    {
      "id": "q50",
      "type": "single_choice",
      "questionText": "在訓練模型時，為了避免模型過度學習訓練集的細節而導致泛化能力下降，通常會在驗證集誤差開始上升時停止迭代。這項技術稱為？",
      "options": [
        { "key": "A", "value": "早停策略 (Early Stopping)" },
        { "key": "B", "value": "梯度消失" },
        { "key": "C", "value": "模型剪枝" },
        { "key": "D", "value": "標記化處理" }
      ],
      "answer": "A",
      "explanation": "早停策略（Early Stopping）是監控模型在驗證集的表現，當效能不再提升甚至開始惡化時，提前終止訓練過程，是防止過擬合的常見手段 [1]。",
      "score": 2,
      "tags": ["模型訓練", "早停策略"]
    }
  ]
}