{
  "level": "junior",
  "type": "人工智慧基礎概論",
  "quiz_id": "114-AI-Subject1-Mock-Set1",
  "title": "114年初級AI應用規劃師第一科：人工智慧基礎概論 (模擬試題一)",
  "questions": [
    {
      "id": "q1",
      "type": "single_choice",
      "questionText": "依據功能不同，主要用於洞悉數據模式、處理大量數據以提供企業見解的 AI 稱為什麼？",
      "options": [
        { "key": "A", "value": "生成型 AI" },
        { "key": "B", "value": "預測型 AI" },
        { "key": "C", "value": "分析型 AI" },
        { "key": "D", "value": "決策型 AI" }
      ],
      "answer": "C",
      "explanation": "分析型 AI 主要用於洞悉數據模式，分析和處理大量數據，以提供有價值的見解 [1]。",
      "score": 2,
      "tags": ["AI概念", "分析型 AI"]
    },
    {
      "id": "q2",
      "type": "single_choice",
      "questionText": "生成式 AI 自 2022 年快速發展，其主要透過使用者輸入何種內容來生成文字、語音、圖像等素材？",
      "options": [
        { "key": "A", "value": "原始碼 (Source Code)" },
        { "key": "B", "value": "提示詞 (Prompt)" },
        { "key": "C", "value": "標籤 (Label)" },
        { "key": "D", "value": "演算法 (Algorithm)" }
      ],
      "answer": "B",
      "explanation": "生成型 AI 可根據使用者輸入的提示詞（prompt），生成各類素材，包括文字、語音、圖像和影片 [1, 2]。",
      "score": 2,
      "tags": ["AI概念", "生成式 AI"]
    },
    {
      "id": "q3",
      "type": "single_choice",
      "questionText": "在金融領域中，AI 實時監控交易行為並偵測異常模式以降低風險，此應用稱為？",
      "options": [
        { "key": "A", "value": "風險評估" },
        { "key": "B", "value": "自動交易" },
        { "key": "C", "value": "欺詐檢測" },
        { "key": "D", "value": "投資組合優化" }
      ],
      "answer": "C",
      "explanation": "欺詐檢測：實時監控交易行為，偵測異常模式以降低詐欺風險 [2, 3]。",
      "score": 2,
      "tags": ["AI應用", "金融領域"]
    },
    {
      "id": "q4",
      "type": "single_choice",
      "questionText": "人工智慧的技術底層包含資料處理、機器學習與深度學習等，下列何者屬於處理「非結構化數據（如語音、影像）」的核心技術？",
      "options": [
        { "key": "A", "value": "深度學習 (Deep Learning)" },
        { "key": "B", "value": "線性迴歸 (Linear Regression)" },
        { "key": "C", "value": "專家系統 (Expert System)" },
        { "key": "D", "value": "關聯分析 (Association Analysis)" }
      ],
      "answer": "A",
      "explanation": "深度學習構建於人工神經網路基礎之上，適用於處理非結構化數據，如語音辨識、影像處理與自然語言處理等 [4]。",
      "score": 2,
      "tags": ["技術底層", "深度學習"]
    },
    {
      "id": "q5",
      "type": "single_choice",
      "questionText": "具有清晰且固定結構，通常以行列形式儲存於關聯式資料庫（如 MySQL）中的數據類型稱為？",
      "options": [
        { "key": "A", "value": "結構化數據 (Structured Data)" },
        { "key": "B", "value": "半結構化數據 (Semi-structured Data)" },
        { "key": "C", "value": "非結構化數據 (Unstructured Data)" },
        { "key": "D", "value": "串流數據 (Streaming Data)" }
      ],
      "answer": "A",
      "explanation": "結構化數據具有清晰且固定結構，通常以行列形式儲存，常見於關聯式資料庫（如 MySQL） [5]。",
      "score": 2,
      "tags": ["資料處理", "數據類型"]
    },
    {
      "id": "q6",
      "type": "single_choice",
      "questionText": "XML 與 JSON 格式的數據，具有一定結構標籤但無需嚴格遵循固定架構，屬於下列哪種數據類型？",
      "options": [
        { "key": "A", "value": "結構化數據" },
        { "key": "B", "value": "半結構化數據" },
        { "key": "C", "value": "非結構化數據" },
        { "key": "D", "value": "圖形數據" }
      ],
      "answer": "B",
      "explanation": "半結構化數據具有一定結構標籤但格式靈活，適用於描述層次化數據，如 XML、JSON、CSV等 [5]。",
      "score": 2,
      "tags": ["資料處理", "數據類型"]
    },
    {
      "id": "q7",
      "type": "single_choice",
      "questionText": "在數據清洗過程中，若數據存在「遺缺值（Missing Value）」，下列哪種處理方式最為常見？",
      "options": [
        { "key": "A", "value": "將所有缺失值改為無限大 (Infinity)" },
        { "key": "B", "value": "隨機填入任意字元" },
        { "key": "C", "value": "使用統計方法（如平均值、中位數）進行填補" },
        { "key": "D", "value": "直接刪除整座資料庫" }
      ],
      "answer": "C",
      "explanation": "處理遺缺值可使用統計方法填補（例如平均值、中位數、眾數等），或利用插補法與預測模型填補 [6, 7]。",
      "score": 2,
      "tags": ["資料清洗", "遺缺值"]
    },
    {
      "id": "q8",
      "type": "single_choice",
      "questionText": "將連續型數據轉換為離散的區間或類別（例如將年齡分為「青年」、「中年」、「老年」），此數據轉換步驟稱為？",
      "options": [
        { "key": "A", "value": "數據標準化" },
        { "key": "B", "value": "數據離散化" },
        { "key": "C", "value": "數據縮減" },
        { "key": "D", "value": "數據格式轉換" }
      ],
      "answer": "B",
      "explanation": "數據離散化（Data Discretization）是指將連續型數據轉換為離散的區間或類別 [8]。",
      "score": 2,
      "tags": ["數據轉換", "離散化"]
    },
    {
      "id": "q9",
      "type": "single_choice",
      "questionText": "主成分分析（PCA）在數據處理與探索性分析中主要用於何種目的？",
      "options": [
        { "key": "A", "value": "增加數據特徵以提高複雜度" },
        { "key": "B", "value": "填補遺缺值" },
        { "key": "C", "value": "減少數據的維度，同時保留大部分的數據資訊" },
        { "key": "D", "value": "將所有非數值資料轉換為數值" }
      ],
      "answer": "C",
      "explanation": "PCA 的特點與用途在於減少數據維度，同時保留大部分數據內訊息，便於視覺化或進一步分析 [8, 9]。",
      "score": 2,
      "tags": ["資料分析", "PCA"]
    },
    {
      "id": "q10",
      "type": "single_choice",
      "questionText": "在描述資料的中央趨勢時，哪一種統計量代表一組資料中「出現頻率最高」的值，且不受極端值影響？",
      "options": [
        { "key": "A", "value": "平均數 (Mean)" },
        { "key": "B", "value": "中位數 (Median)" },
        { "key": "C", "value": "眾數 (Mode)" },
        { "key": "D", "value": "四分位數 (Quartile)" }
      ],
      "answer": "C",
      "explanation": "眾數是指在一組資料中出現頻率最高的值，相較於平均數和中位數，眾數不受極端值影響 [10, 11]。",
      "score": 2,
      "tags": ["敘述統計", "眾數"]
    },
    {
      "id": "q11",
      "type": "single_choice",
      "questionText": "在品質管理中，用來評估產品穩定性的統計量，若數值越大表示資料分散程度越高、品質越不穩定，該統計量為？",
      "options": [
        { "key": "A", "value": "標準差 (Standard Deviation)" },
        { "key": "B", "value": "平均數 (Mean)" },
        { "key": "C", "value": "中位數 (Median)" },
        { "key": "D", "value": "幾何平均數" }
      ],
      "answer": "A",
      "explanation": "標準差較大時，表示資料的分散程度較高。在品質管理中，標準差越大表示產品品質越不穩定 [11]。",
      "score": 2,
      "tags": ["敘述統計", "標準差"]
    },
    {
      "id": "q12",
      "type": "single_choice",
      "questionText": "用於直觀展示「兩個數值變量」之間關係，以判斷其是否具有線性相關或發現異常值的圖表為？",
      "options": [
        { "key": "A", "value": "直方圖 (Histogram)" },
        { "key": "B", "value": "散佈圖 (Scatter plot)" },
        { "key": "C", "value": "折線圖 (Line chart)" },
        { "key": "D", "value": "圓餅圖 (Pie chart)" }
      ],
      "answer": "B",
      "explanation": "散佈圖用於展示兩個變量之間的關係，能直觀地顯示線性相關、非線性相關，並幫助發現異常值 [10, 12]。",
      "score": 2,
      "tags": ["視覺化", "散佈圖"]
    },
    {
      "id": "q13",
      "type": "single_choice",
      "questionText": "在探索性分析中，透過色彩強度展示數據項目之間關聯程度（例如年齡與消費金額的關聯）的圖表稱為？",
      "options": [
        { "key": "A", "value": "熱圖 (Heatmap)" },
        { "key": "B", "value": "箱型圖 (Box Plot)" },
        { "key": "C", "value": "平行坐標圖 (Parallel Coordinates Plot)" },
        { "key": "D", "value": "折線圖 (Line chart)" }
      ],
      "answer": "A",
      "explanation": "熱圖透過色彩強度展示數據項目之間的關聯程度，通常用於相關分析 [13]。",
      "score": 2,
      "tags": ["視覺化", "熱圖"]
    },
    {
      "id": "q14",
      "type": "single_choice",
      "questionText": "在診斷性分析中，從宏觀數據逐層深入到細節層級（例如從總銷售額深入至各地區或產品類別）以尋找問題根本原因的方法是？",
      "options": [
        { "key": "A", "value": "因果分析 (Causal Analysis)" },
        { "key": "B", "value": "關聯分析 (Association Analysis)" },
        { "key": "C", "value": "鑽取/向下分析 (Drill-down Analysis)" },
        { "key": "D", "value": "時間序列分析" }
      ],
      "answer": "C",
      "explanation": "鑽取/向下分析的特點是從宏觀數據逐層深入到細節層級，逐步鎖定問題範圍 [14]。",
      "score": 2,
      "tags": ["診斷性分析", "鑽取分析"]
    },
    {
      "id": "q15",
      "type": "single_choice",
      "questionText": "分析超市購物車數據中「啤酒與尿布」等商品共同被購買的模式，屬於下列哪一種分析方法？",
      "options": [
        { "key": "A", "value": "因果分析" },
        { "key": "B", "value": "關聯分析 (Association Analysis)" },
        { "key": "C", "value": "迴歸預測" },
        { "key": "D", "value": "鑽取分析" }
      ],
      "answer": "B",
      "explanation": "關聯分析分析數據項目之間的共現關係或模式，如 Apriori演算法用於分析「啤酒與尿布的關聯性」 [14]。",
      "score": 2,
      "tags": ["診斷性分析", "關聯分析"]
    },
    {
      "id": "q16",
      "type": "single_choice",
      "questionText": "在預測性分析中，用於預測「連續型數值結果」（例如房地產價格或未來銷售額）的模型通常為？",
      "options": [
        { "key": "A", "value": "分類模型 (Classification Models)" },
        { "key": "B", "value": "聚類模型 (Clustering Models)" },
        { "key": "C", "value": "迴歸模型 (Regression Models)" },
        { "key": "D", "value": "關聯規則模型" }
      ],
      "answer": "C",
      "explanation": "迴歸模型特點與用途為數值型結果的預測，如預測房地產價格、銷售額等 [14, 15]。",
      "score": 2,
      "tags": ["預測性分析", "迴歸模型"]
    },
    {
      "id": "q17",
      "type": "single_choice",
      "questionText": "演算法中，將資料集的中間元素與目標元素比較，並根據大小關係不斷將搜尋範圍縮小一半的方法稱為？",
      "options": [
        { "key": "A", "value": "線性搜尋 (Linear Search)" },
        { "key": "B", "value": "廣度優先搜尋 (BFS)" },
        { "key": "C", "value": "深度優先搜尋 (DFS)" },
        { "key": "D", "value": "二分搜尋 (Binary Search)" }
      ],
      "answer": "D",
      "explanation": "二分搜尋首先將資料集的中間元素與目標元素進行比較，並依大小決定往左半或右半繼續搜尋 [16]。",
      "score": 2,
      "tags": ["演算法", "二分搜尋"]
    },
    {
      "id": "q18",
      "type": "single_choice",
      "questionText": "關於邏輯迴歸（Logistic Regression），下列敘述何者正確？",
      "options": [
        { "key": "A", "value": "專門用來預測連續數值的迴歸演算法" },
        { "key": "B", "value": "雖然名稱有迴歸，但實際上是一種分類演算法，常用於二元分類" },
        { "key": "C", "value": "是一種不需標記數據的非監督式學習演算法" },
        { "key": "D", "value": "只適用於處理圖像數據" }
      ],
      "answer": "B",
      "explanation": "邏輯迴歸雖然名稱中有「迴歸」，但實際上是一種分類演算法，使用 Sigmoid 函數將輸出轉換為機率值來進行決策 [17]。",
      "score": 2,
      "tags": ["演算法", "邏輯迴歸"]
    },
    {
      "id": "q19",
      "type": "single_choice",
      "questionText": "對於一個新的輸入樣本，找出訓練集中與其最接近的 K 個樣本，並以多數決方式進行分類的方法是？",
      "options": [
        { "key": "A", "value": "K-最近鄰演算法 (KNN)" },
        { "key": "B", "value": "K-均值聚類 (K-Means)" },
        { "key": "C", "value": "主成分分析 (PCA)" },
        { "key": "D", "value": "支援向量機 (SVM)" }
      ],
      "answer": "A",
      "explanation": "K-最近鄰演算法（KNN）對於分類問題，會將新樣本分類為 K 個最近鄰中出現次數最多的類別 [17, 18]。",
      "score": 2,
      "tags": ["演算法", "KNN"]
    },
    {
      "id": "q20",
      "type": "single_choice",
      "questionText": "機器學習中，使用「帶有明確標記（Labeled Data）」的數據來訓練模型，以學習輸入與輸出之間映射關係的方法稱為？",
      "options": [
        { "key": "A", "value": "非監督式學習" },
        { "key": "B", "value": "強化學習" },
        { "key": "C", "value": "監督式學習 (Supervised Learning)" },
        { "key": "D", "value": "自監督學習" }
      ],
      "answer": "C",
      "explanation": "監督式學習以「有標記的數據」為基礎，目標在於學習輸入與輸出之間的映射關係 [18, 19]。",
      "score": 2,
      "tags": ["機器學習", "監督式學習"]
    },
    {
      "id": "q21",
      "type": "single_choice",
      "questionText": "不依賴已標記的數據，而是自動從數據中發掘潛在的結構或模式，主要應用於「聚類（Clustering）」與「降維」的學習方法是？",
      "options": [
        { "key": "A", "value": "監督式學習" },
        { "key": "B", "value": "非監督式學習 (Unsupervised Learning)" },
        { "key": "C", "value": "強化學習" },
        { "key": "D", "value": "深度學習" }
      ],
      "answer": "B",
      "explanation": "非監督式學習不依賴有標記的數據，核心目標包括「聚類」和「降維」，如 K-Means 和 PCA [20, 21]。",
      "score": 2,
      "tags": ["機器學習", "非監督式學習"]
    },
    {
      "id": "q22",
      "type": "single_choice",
      "questionText": "基於「試錯學習（Trial-and-Error）」機制，代理（Agent）透過與環境互動並根據「獎勵（Reward）」來優化最佳行動策略的方法是？",
      "options": [
        { "key": "A", "value": "監督式學習" },
        { "key": "B", "value": "非監督式學習" },
        { "key": "C", "value": "強化學習 (Reinforcement Learning)" },
        { "key": "D", "value": "線性迴歸" }
      ],
      "answer": "C",
      "explanation": "強化學習的核心目標是讓代理透過探索環境執行行動，並根據獎勵不斷更新策略，反映試錯學習本質 [20, 22]。",
      "score": 2,
      "tags": ["機器學習", "強化學習"]
    },
    {
      "id": "q23",
      "type": "single_choice",
      "questionText": "在深度學習架構中，特別擅長處理「圖像數據」，並依賴卷積層（Convolutional Layer）與池化層來提取特徵的模型是？",
      "options": [
        { "key": "A", "value": "卷積神經網路 (CNN)" },
        { "key": "B", "value": "循環神經網路 (RNN)" },
        { "key": "C", "value": "生成對抗網路 (GAN)" },
        { "key": "D", "value": "變分自編碼器 (VAE)" }
      ],
      "answer": "A",
      "explanation": "卷積神經網路（CNN）靈感來自生物視覺皮層，包含卷積層與池化層，特別擅長處理圖像數據 [23]。",
      "score": 2,
      "tags": ["深度學習", "CNN"]
    },
    {
      "id": "q24",
      "type": "single_choice",
      "questionText": "專為處理「序列數據（如語音、文本）」設計，並能記住前一時刻狀態以捕捉時間依賴關係的模型是？",
      "options": [
        { "key": "A", "value": "CNN" },
        { "key": "B", "value": "循環神經網路 (RNN)" },
        { "key": "C", "value": "隨機森林 (Random Forest)" },
        { "key": "D", "value": "支援向量機 (SVM)" }
      ],
      "answer": "B",
      "explanation": "RNN 專為處理序列數據設計，每個節點接收當前輸入並記住前一時刻狀態，適合語音與文本 [24]。",
      "score": 2,
      "tags": ["深度學習", "RNN"]
    },
    {
      "id": "q25",
      "type": "single_choice",
      "questionText": "生成對抗網路（GAN）由哪兩個核心神經網路組成，並透過對抗學習共同進步以生成高品質數據？",
      "options": [
        { "key": "A", "value": "編碼器 (Encoder) 與解碼器 (Decoder)" },
        { "key": "B", "value": "生成器 (Generator) 與判別器 (Discriminator)" },
        { "key": "C", "value": "客戶端 (Client) 與伺服器 (Server)" },
        { "key": "D", "value": "卷積層 (Conv Layer) 與池化層 (Pooling Layer)" }
      ],
      "answer": "B",
      "explanation": "GAN 由生成器和判別器（鑑別器）組成，生成器負責生成數據欺騙判別器，判別器區分真假 [25, 26]。",
      "score": 2,
      "tags": ["深度學習", "GAN"]
    },
    {
      "id": "q26",
      "type": "single_choice",
      "questionText": "在 AI 模型訓練過程中，用來根據損失函數結果「更新模型參數」，使模型誤差越來越小的組件稱為？",
      "options": [
        { "key": "A", "value": "提示詞 (Prompt)" },
        { "key": "B", "value": "優化器 (Optimizer)" },
        { "key": "C", "value": "核函數 (Kernel Function)" },
        { "key": "D", "value": "損失函數 (Loss Function)" }
      ],
      "answer": "B",
      "explanation": "系統會不斷計算損失，並透過優化器（如 Adam、SGD）更新模型參數，以最小化損失 [27, 28]。",
      "score": 2,
      "tags": ["模型訓練", "優化器"]
    },
    {
      "id": "q27",
      "type": "single_choice",
      "questionText": "在資料分析前，為了消除不同特徵之間的尺度差異（如收入與年齡的數值落差），常將數據縮放到統一範圍（如 0 到 1），此步驟稱為？",
      "options": [
        { "key": "A", "value": "數據離散化" },
        { "key": "B", "value": "數據標準化 / 正規化 (Standardization/Normalization)" },
        { "key": "C", "value": "數據格式轉換" },
        { "key": "D", "value": "遺缺值填補" }
      ],
      "answer": "B",
      "explanation": "數據標準化（如 Min-Max Scaling 或 Z-score）旨在將數據轉換到統一範圍，消除尺度差異提升模型效果 [29]。",
      "score": 2,
      "tags": ["資料處理", "數據標準化"]
    },
    {
      "id": "q28",
      "type": "single_choice",
      "questionText": "用來衡量模型預測值與實際目標之間差異的函數，且該數值越高代表模型預測不準確度越大的函數稱為？",
      "options": [
        { "key": "A", "value": "核函數 (Kernel Function)" },
        { "key": "B", "value": "損失函數 (Loss Function)" },
        { "key": "C", "value": "激勵函數 (Activation Function)" },
        { "key": "D", "value": "目標函數" }
      ],
      "answer": "B",
      "explanation": "損失函數用來衡量預測值與實際目標的差異，損失值越高表示誤差越大 [28]。",
      "score": 2,
      "tags": ["模型訓練", "損失函數"]
    },
    {
      "id": "q29",
      "type": "single_choice",
      "questionText": "模型在訓練數據上表現優異，但在未見過的測試數據上表現不佳。為了防範這種「過擬合（Overfitting）」現象，常採用下列哪一種策略？",
      "options": [
        { "key": "A", "value": "減少訓練數據量" },
        { "key": "B", "value": "加入正則化 (Regularization) 或採用早停策略 (Early Stopping)" },
        { "key": "C", "value": "增加神經網路的層數與複雜度" },
        { "key": "D", "value": "使用均方誤差替代交叉熵" }
      ],
      "answer": "B",
      "explanation": "防範過擬合通常採用 Regularization（如 L1/L2 正則化）、Early Stopping 以及數據增強 (Data Augmentation) [30]。",
      "score": 2,
      "tags": ["模型優化", "過擬合"]
    },
    {
      "id": "q30",
      "type": "single_choice",
      "questionText": "透過將數據集平均分割為多個子集，反覆選擇不同子集進行訓練與測試，以評估模型泛化能力與穩健性的技術稱為？",
      "options": [
        { "key": "A", "value": "A/B 測試" },
        { "key": "B", "value": "交叉驗證 (Cross-Validation)" },
        { "key": "C", "value": "網格搜索 (Grid Search)" },
        { "key": "D", "value": "貝葉斯優化" }
      ],
      "answer": "B",
      "explanation": "交叉驗證（如 K 折交叉驗證）是透過分割數據反覆訓練與測試，有效降低過擬合風險並提升泛化能力的技術 [31]。",
      "score": 2,
      "tags": ["模型評估", "交叉驗證"]
    },
    {
      "id": "q31",
      "type": "single_choice",
      "questionText": "在鑑別式 AI 中，透過引入「核函數（Kernel Function）」將線性不可分數據映射到高維空間以找到最佳分類邊界的模型是？",
      "options": [
        { "key": "A", "value": "決策樹 (Decision Tree)" },
        { "key": "B", "value": "邏輯迴歸 (Logistic Regression)" },
        { "key": "C", "value": "支援向量機 (Support Vector Machine, SVM)" },
        { "key": "D", "value": "卷積神經網路 (CNN)" }
      ],
      "answer": "C",
      "explanation": "SVM 透過核函數將數據映射到高維特徵空間，尋找能最大化類別間隔的超平面進行非線性分類 [32, 33]。",
      "score": 2,
      "tags": ["演算法", "SVM"]
    },
    {
      "id": "q32",
      "type": "single_choice",
      "questionText": "透過構建多棵決策樹，並取其結果的平均值或投票結果，以提升模型準確性並降低過擬合風險的集成學習方法是？",
      "options": [
        { "key": "A", "value": "線性迴歸" },
        { "key": "B", "value": "隨機森林 (Random Forest)" },
        { "key": "C", "value": "K-均值聚類" },
        { "key": "D", "value": "主成分分析" }
      ],
      "answer": "B",
      "explanation": "隨機森林是決策樹的集成學習方法，透過構建多棵獨立的決策樹並進行投票或平均來預測 [34]。",
      "score": 2,
      "tags": ["集成學習", "隨機森林"]
    },
    {
      "id": "q33",
      "type": "single_choice",
      "questionText": "下列何種生成式模型透過「編碼器」將數據映射到隱變量空間（Latent Space），再由「解碼器」重建原始數據，常用於異常檢測與數據修復？",
      "options": [
        { "key": "A", "value": "生成對抗網路 (GAN)" },
        { "key": "B", "value": "變分自編碼器 (VAE)" },
        { "key": "C", "value": "擴散模型 (Diffusion Models)" },
        { "key": "D", "value": "循環神經網路 (RNN)" }
      ],
      "answer": "B",
      "explanation": "VAE 包含編碼器與解碼器，透過映射到隱變量空間並重建數據，廣泛應用於數據生成與異常檢測 [35]。",
      "score": 2,
      "tags": ["生成式 AI", "VAE"]
    },
    {
      "id": "q34",
      "type": "single_choice",
      "questionText": "透過向數據逐步添加隨機雜訊，再經過反向過程逐步去除雜訊以重建真實感數據，特別適合生成高品質圖像的模型是？",
      "options": [
        { "key": "A", "value": "卷積神經網路 (CNN)" },
        { "key": "B", "value": "生成對抗網路 (GAN)" },
        { "key": "C", "value": "變分自編碼器 (VAE)" },
        { "key": "D", "value": "擴散模型 (Diffusion Models)" }
      ],
      "answer": "D",
      "explanation": "擴散模型基於逐步添加與去除雜訊的過程，在生成高分辨率且細節豐富的圖像任務中表現出色 [36]。",
      "score": 2,
      "tags": ["生成式 AI", "擴散模型"]
    },
    {
      "id": "q35",
      "type": "single_choice",
      "questionText": "鑑別式 AI 與生成式 AI 的主要技術目標差異為何？",
      "options": [
        { "key": "A", "value": "兩者完全相同，皆為生成新數據" },
        { "key": "B", "value": "鑑別式 AI 專注於學習分類與預測邊界；生成式 AI 側重於學習數據分佈並生成新內容" },
        { "key": "C", "value": "鑑別式 AI 無法處理影像，生成式 AI 只能處理文字" },
        { "key": "D", "value": "鑑別式 AI 採用無監督學習，生成式 AI 採用監督學習" }
      ],
      "answer": "B",
      "explanation": "鑑別式 AI 學習決策邊界進行分類或預測（P(y|x)）；生成式 AI 側重學習數據分佈（P(x)）以創造新內容 [37, 38]。",
      "score": 2,
      "tags": ["AI 概念", "生成與鑑別"]
    },
    {
      "id": "q36",
      "type": "single_choice",
      "questionText": "在鑑別式 AI 面臨的挑戰中，模型可能在分類時過度放大了訓練資料集裡的不均衡特性，影響決策的公平性，此挑戰稱為什麼？",
      "options": [
        { "key": "A", "value": "數據偏見 (Bias in Data)" },
        { "key": "B", "value": "模式崩潰 (Mode Collapse)" },
        { "key": "C", "value": "過擬合 (Overfitting)" },
        { "key": "D", "value": "標記成本 (Labeling Cost)" }
      ],
      "answer": "A",
      "explanation": "數據偏見是指模型可能會在分類時學習到數據的偏見，影響公平性與準確性 [38]。",
      "score": 2,
      "tags": ["AI 挑戰", "數據偏見"]
    },
    {
      "id": "q37",
      "type": "single_choice",
      "questionText": "在醫療影像分析中，若遇到罕見疾病真實病理影像稀缺的問題，利用哪一項 AI 技術可以生成高品質的模擬影像來擴充訓練集？",
      "options": [
        { "key": "A", "value": "決策樹" },
        { "key": "B", "value": "生成對抗網路等生成式 AI" },
        { "key": "C", "value": "K-均值聚類" },
        { "key": "D", "value": "專家系統" }
      ],
      "answer": "B",
      "explanation": "生成式 AI (如 GAN) 可以生成高品質的病變模擬影像以擴充訓練集，解決數據稀缺問題並提高模型泛化效能 [39, 40]。",
      "score": 2,
      "tags": ["AI 整合應用", "醫療影像"]
    },
    {
      "id": "q38",
      "type": "single_choice",
      "questionText": "在自動駕駛的技術發展中，生成式 AI 與鑑別式 AI 最典型的協同運作模式是？",
      "options": [
        { "key": "A", "value": "鑑別式 AI 負責畫地圖，生成式 AI 控制煞車" },
        { "key": "B", "value": "生成式 AI 模擬冰雪、濃霧等複雜環境場景，鑑別式 AI 據此進行環境識別與決策規劃" },
        { "key": "C", "value": "兩者分別負責白天與晚上的駕駛" },
        { "key": "D", "value": "完全依賴生成式 AI 決定方向盤轉動角度" }
      ],
      "answer": "B",
      "explanation": "生成式 AI 可生成極端天氣等虛擬駕駛場景，幫助鑑別式 AI 模型學習應對複雜情境的決策策略 [40, 41]。",
      "score": 2,
      "tags": ["AI 整合應用", "自動駕駛"]
    },
    {
      "id": "q39",
      "type": "single_choice",
      "questionText": "在智慧客服系統的整合應用中，生成式 AI 負責生成自然流暢的回應，而鑑別式 AI 通常負責什麼任務以確保服務品質？",
      "options": [
        { "key": "A", "value": "記錄通話時間" },
        { "key": "B", "value": "為客戶播放背景音樂" },
        { "key": "C", "value": "過濾不當內容與合規性檢測" },
        { "key": "D", "value": "自動掛斷客戶電話" }
      ],
      "answer": "C",
      "explanation": "生成式 AI 負責生成多樣化回應文本，鑑別式 AI 負責過濾不當內容並進行合規性檢測 [42]。",
      "score": 2,
      "tags": ["AI 整合應用", "智慧客服"]
    },
    {
      "id": "q40",
      "type": "single_choice",
      "questionText": "生成對抗網路（GAN）在訓練過程中，生成器可能只學會產出少數幾種樣本，導致生成數據缺乏多樣性，這種不穩定的現象稱為什麼？",
      "options": [
        { "key": "A", "value": "模式崩潰 (Mode Collapse)" },
        { "key": "B", "value": "梯度消失 (Vanishing Gradient)" },
        { "key": "C", "value": "維度災難 (Curse of Dimensionality)" },
        { "key": "D", "value": "災難性遺忘 (Catastrophic Forgetting)" }
      ],
      "answer": "A",
      "explanation": "GAN 的訓練過程不穩定，可能出現模式崩潰（Mode Collapse），導致生成數據多樣性不足 [42, 43]。",
      "score": 2,
      "tags": ["模型挑戰", "GAN"]
    },
    {
      "id": "q41",
      "type": "single_choice",
      "questionText": "當一組資料存在明顯的極端值（如多數薪資為 3 萬，但有極少數為 300 萬）時，下列哪一種統計量最能準確反映資料的中心趨勢，而不受極端值拉抬？",
      "options": [
        { "key": "A", "value": "算術平均數 (Mean)" },
        { "key": "B", "value": "全距 (Range)" },
        { "key": "C", "value": "中位數 (Median)" },
        { "key": "D", "value": "標準差 (Standard Deviation)" }
      ],
      "answer": "C",
      "explanation": "相較於平均數，中位數不易受到極端值影響，更能反映偏態資料的典型水平或中心趨勢 [44, 45]。",
      "score": 2,
      "tags": ["敘述統計", "中位數"]
    },
    {
      "id": "q42",
      "type": "single_choice",
      "questionText": "在資料分析的兩大類別中，「探索性資料分析 (EDA)」與「驗證性資料分析 (CDA)」的最大差異在於？",
      "options": [
        { "key": "A", "value": "EDA 只能處理文字資料，CDA 處理數值資料" },
        { "key": "B", "value": "EDA 強調無需預設假設的靈活探索以生成假設，CDA 著重於驗證已知假設" },
        { "key": "C", "value": "EDA 不需要使用任何圖表，CDA 強烈依賴圖表" },
        { "key": "D", "value": "EDA 主要運用深度學習，CDA 主要運用機器學習" }
      ],
      "answer": "B",
      "explanation": "EDA 是一種靈活開放的過程，用於發現模式並生成假設；而 CDA 則注重驗證研究者已提出的假設 [12, 46]。",
      "score": 2,
      "tags": ["資料分析", "EDA與CDA"]
    },
    {
      "id": "q43",
      "type": "single_choice",
      "questionText": "在強化學習架構中，代理 (Agent) 執行某個行動後，由環境反饋給代理用來表示該行動好壞的評估訊號，稱為什麼？",
      "options": [
        { "key": "A", "value": "狀態 (State)" },
        { "key": "B", "value": "策略 (Policy)" },
        { "key": "C", "value": "獎勵 (Reward)" },
        { "key": "D", "value": "損失 (Loss)" }
      ],
      "answer": "C",
      "explanation": "獎勵（Reward）是代理在執行某一行動後獲得的回饋，用來表示該行動的好壞，代理的目標是最大化累積獎勵 [22]。",
      "score": 2,
      "tags": ["強化學習", "獎勵"]
    },
    {
      "id": "q44",
      "type": "single_choice",
      "questionText": "Deep Q-Learning（DQN）相較於傳統基於表格的 Q-Learning，其最主要的技術突破是什麼？",
      "options": [
        { "key": "A", "value": "完全捨棄了獎勵機制" },
        { "key": "B", "value": "結合深度學習神經網路來近似 Q 值，解決高維度狀態空間難以計算的問題" },
        { "key": "C", "value": "轉變為監督式學習，不再需要與環境互動" },
        { "key": "D", "value": "只能應用於文字生成任務" }
      ],
      "answer": "B",
      "explanation": "DQN 結合深度學習來解決 Q-Learning 在高維度環境中（因需儲存龐大 Q 表）的限制 [47]。",
      "score": 2,
      "tags": ["強化學習", "DQN"]
    },
    {
      "id": "q45",
      "type": "single_choice",
      "questionText": "訓練機器學習模型時，針對「數值型預測任務」（如預測股票價格），最常採用下列哪一種損失函數來評估誤差？",
      "options": [
        { "key": "A", "value": "交叉熵損失 (Cross-Entropy Loss)" },
        { "key": "B", "value": "均方誤差 (Mean Squared Error, MSE)" },
        { "key": "C", "value": "準確率 (Accuracy)" },
        { "key": "D", "value": "F1 分數 (F1 Score)" }
      ],
      "answer": "B",
      "explanation": "均方誤差（MSE）主要用於迴歸任務，計算預測值與真實值之間平方誤差的平均值 [28]。",
      "score": 2,
      "tags": ["模型優化", "損失函數"]
    },
    {
      "id": "q46",
      "type": "single_choice",
      "questionText": "傳統的循環神經網路（RNN）在處理長序列時容易面臨梯度消失問題。為了解決此限制並捕捉長期時間依賴關係，最常使用下列哪種改良模型？",
      "options": [
        { "key": "A", "value": "支援向量機 (SVM)" },
        { "key": "B", "value": "卷積層 (Convolutional Layer)" },
        { "key": "C", "value": "長短期記憶網路 (LSTM)" },
        { "key": "D", "value": "K-平均聚類 (K-Means)" }
      ],
      "answer": "C",
      "explanation": "長短期記憶網路（LSTM）透過引入遺忘門、輸入門和輸出門，有效解決了標準 RNN 的梯度消失問題 [24]。",
      "score": 2,
      "tags": ["深度學習", "LSTM"]
    },
    {
      "id": "q47",
      "type": "single_choice",
      "questionText": "企業利用「網路爬蟲 (Web Scraping)」自動擷取各大網站上的商品評論或新聞文章。透過此方法收集到的數據大多屬於哪種類型？",
      "options": [
        { "key": "A", "value": "高度結構化且已清理的關聯式數據" },
        { "key": "B", "value": "僅包含數字的二進制數據" },
        { "key": "C", "value": "非結構化或半結構化數據" },
        { "key": "D", "value": "具有精確標記的監督學習專用數據" }
      ],
      "answer": "C",
      "explanation": "網路爬蟲抓取的新聞、評論等文本數據大多屬於非結構化或半結構化數據，需經處理後方能分析 [5, 6]。",
      "score": 2,
      "tags": ["數據蒐集", "爬蟲"]
    },
    {
      "id": "q48",
      "type": "single_choice",
      "questionText": "在統計的假設檢定中，若計算出的 p 值（p-value）小於設定的顯著水準（例如 0.05），這代表分析者應該做出什麼決策？",
      "options": [
        { "key": "A", "value": "接受虛無假設 (Accept Null Hypothesis)" },
        { "key": "B", "value": "拒絕虛無假設 (Reject Null Hypothesis)" },
        { "key": "C", "value": "放棄數據重新採樣" },
        { "key": "D", "value": "將數據進行標準化處理" }
      ],
      "answer": "B",
      "explanation": "若所得之觀測值的 p 值夠小（小於顯著水準 α），表示在虛無假設下極不可能發生，因此拒絕虛無假設 [46]。",
      "score": 2,
      "tags": ["統計學", "假設檢定"]
    },
    {
      "id": "q49",
      "type": "single_choice",
      "questionText": "在模型訓練完畢後，為了尋找最佳的「超參數（Hyperparameters）」，在預定範圍內逐一嘗試所有參數組合的方法稱為？",
      "options": [
        { "key": "A", "value": "網格搜索 (Grid Search)" },
        { "key": "B", "value": "隨機搜索 (Random Search)" },
        { "key": "C", "value": "梯度下降 (Gradient Descent)" },
        { "key": "D", "value": "反向傳播 (Backpropagation)" }
      ],
      "answer": "A",
      "explanation": "模型調參中，網格搜索（Grid Search）是在預定範圍內逐一嘗試所有的超參數組合以尋找最佳設置 [31]。",
      "score": 2,
      "tags": ["模型優化", "超參數調校"]
    },
    {
      "id": "q50",
      "type": "single_choice",
      "questionText": "將資料中的日期格式由「YYYY/MM/DD」統一轉換為「YYYY-MM-DD」，或將字串轉換為數值，這屬於資料處理流程中的哪一個步驟？",
      "options": [
        { "key": "A", "value": "數據蒐集 (Data Collection)" },
        { "key": "B", "value": "數據分析 (Data Analysis)" },
        { "key": "C", "value": "數據轉換 (Data Transformation)" },
        { "key": "D", "value": "探索性分析 (EDA)" }
      ],
      "answer": "C",
      "explanation": "數據格式轉換與數據類型轉換（如將字串轉為數值或統一格式）皆屬於數據轉換（Data Transformation）的環節 [8]。",
      "score": 2,
      "tags": ["資料處理", "數據轉換"]
    }
  ]
}