{
  "type": "人工智慧基礎概論",
  "quiz_id": "114-4-AI-Subject1",
  "title": "114年第四梯次初級AI應用規劃師第一科：人工智慧基礎概論",
  "exam_date": "2025-11-01",
  "questions": [
    {
      "id": "q1",
      "type": "single_choice",
      "questionText": "在人工智慧系統的決策流程中，下列哪一種情境最符合「人在迴圈上（Human-over-the-loop）」所強調的監督機制？",
      "options": [
        { "key": "A", "value": "AI系統只能提供建議，人類需主動下達命令才能進行決策" },
        { "key": "B", "value": "人類對 AI的運行進行日常監督，必要時可立即介入修正或干預" },
        { "key": "C", "value": "人類平時不參與 AI 的運作，僅在發生異常或重大錯誤時才接手控制" },
        { "key": "D", "value": "AI的所有判斷與行動在執行前，皆須經過人類逐一審核與批准" }
      ],
      "answer": "B",
      "explanation": "「人在迴圈上（Human-over-the-loop）」強調人類扮演監督者角色，AI 可自主執行，但人類監控並在必要時介入。選項 A 和 D 偏向 Human-in-the-loop（每一步需人類參與），C 偏向 Human-out-of-the-loop 或例外管理。",
      "score": 2,
      "tags": ["AI監管", "Human-over-the-loop"]
    },
    {
      "id": "q2",
      "type": "single_choice",
      "questionText": "下列哪一種特徵工程技巧，最適合將「星期幾」和「24 小時制時間」這兩個欄位結合，以預測通勤時間？",
      "options": [
        { "key": "A", "value": "One-hot 編碼（One-hot encoding）" },
        { "key": "B", "value": "正規化（Normalization）" },
        { "key": "C", "value": "特徵交叉（Feature Cross）" },
        { "key": "D", "value": "寬深模型（Wide and Deep）" }
      ],
      "answer": "C",
      "explanation": "特徵交叉（Feature Cross）能捕捉兩個特徵組合後的非線性關係。例如「週一」且「8點」的交通狀況，與「週日」且「8點」截然不同，交叉後能讓模型學習這種特定組合的權重。",
      "score": 2,
      "tags": ["特徵工程", "Feature Cross"]
    },
    {
      "id": "q3",
      "type": "single_choice",
      "questionText": "關於 ETL（Extract-Transform-Load），下列敘述何者為正確？",
      "options": [
        { "key": "A", "value": "E表示將資料直接儲存至目標儲存庫" },
        { "key": "B", "value": "ETL的處理順序可以自由調整為 TEL" },
        { "key": "C", "value": "L表示將目標儲存庫經過反加密處理載入資料" },
        { "key": "D", "value": "T包括資料的清理與排序" }
      ],
      "answer": "D",
      "explanation": "ETL 中，T 代表轉換（Transform），包含資料清理、格式轉換、排序與聚合等處理。E 是抽取（Extract），L 是載入（Load）。",
      "score": 2,
      "tags": ["資料工程", "ETL"]
    },
    {
      "id": "q4",
      "type": "single_choice",
      "questionText": "關於資料正則化（Regularization）L1、L2方法，下列敘述何者正確？",
      "options": [
        { "key": "A", "value": "L1權重個數愈多，愈可以提升模型的正確率" },
        { "key": "B", "value": "L2稱為 Lasso正則化" },
        { "key": "C", "value": "L1運用減少權重的絕對值來控制模型的複雜度" },
        { "key": "D", "value": "L2較 L1 正則化方法會將特徵權重趨近於零" }
      ],
      "answer": "C",
      "explanation": "L1 正則化（Lasso）加入權重的絕對值作為懲罰項，能促使不重要的特徵權重變為零（稀疏化）。L2（Ridge）則是加入權重的平方，只會讓權重變小但不易為零。",
      "score": 2,
      "tags": ["正則化", "L1/L2"]
    },
    {
      "id": "q5",
      "type": "single_choice",
      "questionText": "在機器學習中，「偏差與變異權衡（Bias-Variance Tradeoff）」主要用來解決下列哪一類型的問題？",
      "options": [
        { "key": "A", "value": "因資料來源或收集方式限制，導致模型學習到的資訊不足" },
        { "key": "B", "value": "測試資料樣本與訓練資料高度重複，造成模型泛化能力評估失準" },
        { "key": "C", "value": "訓練資料中類別分布不均，使模型在少數類別上表現不佳" },
        { "key": "D", "value": "如何在模型偏差與變異之間取得平衡，以避免過度擬合或欠擬合" }
      ],
      "answer": "D",
      "explanation": "偏差（Bias）過高導致欠擬合，變異（Variance）過高導致過度擬合。權衡（Tradeoff）的目的就是在兩者間找到平衡點，使總誤差最小化。",
      "score": 2,
      "tags": ["模型評估", "Bias-Variance"]
    },
    {
      "id": "q6",
      "type": "single_choice",
      "questionText": "在 Lasso 模型中，L1 正則化（Regularization）導致參數收斂為零的原因為何？",
      "options": [
        { "key": "A", "value": "L1正則化忽略目標變數" },
        { "key": "B", "value": "L1對梯度有平滑作用" },
        { "key": "C", "value": "L1對大係數懲罰較強，促使稀疏解" },
        { "key": "D", "value": "L1會轉換損失函數為非凸形" }
      ],
      "answer": "C",
      "explanation": "L1 正則化的幾何特性（菱形限制區域）容易與損失函數的等高線在座標軸上相切，這會導致部分參數的最佳解剛好為零，產生稀疏模型（Sparse Model）。",
      "score": 2,
      "tags": ["Lasso", "L1"]
    },
    {
      "id": "q7",
      "type": "single_choice",
      "questionText": "貝氏分類器（Naive Bayes Classifier）常被應用於文字分類、垃圾郵件過濾等場景。依據模型特性，它最適合歸類於下列哪一類？",
      "options": [
        { "key": "A", "value": "透過直接學習輸入特徵與目標標籤之間的邊界或關係來進行分類的模型" },
        { "key": "B", "value": "透過建構資料的整體分布，並利用條件關係進行推斷和分類的模型" },
        { "key": "C", "value": "側重探索資料中樣本間的相似性，將資料自動分成不同群組的模型" },
        { "key": "D", "value": "透過試錯學習，根據行動結果的獎勵或懲罰來優化決策策略的模型" }
      ],
      "answer": "B",
      "explanation": "貝氏分類器屬於生成式模型（Generative Model），它透過學習特徵與類別的聯合機率分佈，再利用貝氏定理計算條件機率來進行分類。",
      "score": 2,
      "tags": ["貝氏分類器", "生成式模型"]
    },
    {
      "id": "q8",
      "type": "single_choice",
      "questionText": "為提升生成式 AI系統回應的語境一致性，常會結合哪類模型技術？",
      "options": [
        { "key": "A", "value": "決策樹分類器（Decision Tree Classifier）" },
        { "key": "B", "value": "條件語言模型（Conditional Language Model）" },
        { "key": "C", "value": "強化學習 Q-learning函數模型" },
        { "key": "D", "value": "基因演算法（Genetic Algorithm）" }
      ],
      "answer": "B",
      "explanation": "生成式 AI（如 GPT）本質上是條件語言模型，它根據給定的前文（條件）來預測下一個字，以確保生成的內容在語境上前後連貫。",
      "score": 2,
      "tags": ["生成式AI", "NLP"]
    },
    {
      "id": "q9",
      "type": "single_choice",
      "questionText": "根據 2025年 9月行政院通過之《人工智慧基本法》草案，政府推動人工智慧之「創新實驗環境」制度，主要參考歐盟的何種制度？",
      "options": [
        { "key": "A", "value": "Data Protection Impact Assessment" },
        { "key": "B", "value": "Regulatory Sandbox" },
        { "key": "C", "value": "AI Trust Label" },
        { "key": "D", "value": "AI Ethics Review Board" }
      ],
      "answer": "B",
      "explanation": "「監理沙盒（Regulatory Sandbox）」制度允許企業在受控的環境中測試創新技術，暫時豁免部分法規限制，以促進 AI 發展與創新。",
      "score": 2,
      "tags": ["AI法規", "監理沙盒"]
    },
    {
      "id": "q10",
      "type": "single_choice",
      "questionText": "根據《金融機構運用人工智慧技術作業規範》，金融機構須建立內部治理架構，並指定專責單位或人員負責推動及管理人工智慧事務，下列何者並非規範所明訂須落實的治理措施？",
      "options": [
        { "key": "A", "value": "辦理人工智慧人才培育" },
        { "key": "B", "value": "清楚了解生成式 AI 技術之運作模式" },
        { "key": "C", "value": "每日公布人工智慧系統運作狀況" },
        { "key": "D", "value": "指派高階主管或委員會進行監督管理" }
      ],
      "answer": "C",
      "explanation": "金融規範強調治理架構、人才培育與高階監督，但並未強制要求「每日」對外公布系統運作狀況，這不符合實務效益與資安考量。",
      "score": 2,
      "tags": ["AI治理", "金融規範"]
    },
    {
      "id": "q11",
      "type": "single_choice",
      "questionText": "下列哪一類問題最適合使用非監督式學習（Unsupervised Learning）來處理？",
      "options": [
        { "key": "A", "value": "根據已標記的醫療影像訓練模型診斷疾病" },
        { "key": "B", "value": "根據使用者行為將用戶分群，以優化行銷策略" },
        { "key": "C", "value": "透過已知交通事故記錄預測未來事故發生機率" },
        { "key": "D", "value": "根據歷史股價預測未來股市的走勢" }
      ],
      "answer": "B",
      "explanation": "非監督式學習不依賴標籤數據。「用戶分群（Clustering）」是典型的非監督任務，旨在發現資料中的潛在結構或群體。",
      "score": 2,
      "tags": ["非監督式學習", "分群"]
    },
    {
      "id": "q12",
      "type": "single_choice",
      "questionText": "下列哪一種圖表最適合用來呈現並分析「兩個數值型變數」之間的關係，例如觀察身高與體重的相關性？",
      "options": [
        { "key": "A", "value": "散佈圖（Scatter Plot）" },
        { "key": "B", "value": "折線圖（Line Chart）" },
        { "key": "C", "value": "直方圖（Histogram）" },
        { "key": "D", "value": "長條圖（Bar Chart）" }
      ],
      "answer": "A",
      "explanation": "散佈圖（Scatter Plot）透過 X 軸與 Y 軸呈現兩個連續變數的數值，是觀察變數間相關性（Correlation）的標準圖表。",
      "score": 2,
      "tags": ["資料視覺化", "散佈圖"]
    },
    {
      "id": "q13",
      "type": "single_choice",
      "questionText": "下列哪一項應用情境與機器學習類型搭配正確？",
      "options": [
        { "key": "A", "value": "在醫療影像資料中，僅有少部分影像有專家標註診斷，其餘大多數影像未標註，研究者結合已標註與未標註資料來建立模型 — 監督式學習（Supervised Learning）" },
        { "key": "B", "value": "在自駕車模擬環境中，模型透過試駕獲得「是否安全通過路口」的獎勵或懲罰訊號，逐步調整決策策略 — 非監督式學習（Unsupervised Learning）" },
        { "key": "C", "value": "在顧客購買紀錄中，利用已知的「顧客是否流失」標籤，訓練模型以預測新顧客未來是否會流失 — 強化式學習（Reinforcement Learning）" },
        { "key": "D", "value": "在股票市場資料中，輸入歷史股價序列，嘗試將未來可能走勢劃分成若干「上升型、盤整型、下降型」群組，無需使用任何標籤 — 非監督式學習（Unsupervised Learning）" }
      ],
      "answer": "D",
      "explanation": "選項 D 描述的是將資料自動「分群」，且不使用標籤，符合非監督式學習。A 是半監督學習，B 是強化學習，C 是監督式學習。",
      "score": 2,
      "tags": ["機器學習類型", "非監督式學習"]
    },
    {
      "id": "q14",
      "type": "single_choice",
      "questionText": "某企業分析團隊正在處理一組近兩年的營運與銷售數據，共有四個部門提出了各自的分析需求，請判斷哪一個最接近「預測性分析（Predictive Analysis）」的特性？",
      "options": [
        { "key": "A", "value": "視覺化所有產品線過去月銷售走勢與標準差，觀察其分佈情況與波動程度" },
        { "key": "B", "value": "藉由資料比對分析，找出去年母親節促銷失效的地區與品類組合" },
        { "key": "C", "value": "建構模型推算下一季的主力商品銷量，以規劃備貨與倉儲資源配置" },
        { "key": "D", "value": "透過熱圖分析廣告投放成本與訂單轉換率之間的潛在關聯性" }
      ],
      "answer": "C",
      "explanation": "預測性分析的重點在於「推算未來」。選項 C 預測下一季銷量，屬於此類。A 是描述性分析，B 是診斷性分析。",
      "score": 2,
      "tags": ["資料分析", "預測性分析"]
    },
    {
      "id": "q15",
      "type": "single_choice",
      "questionText": "某模型使用 K-近鄰演算法（KNN）進行分類，K設為 3。 一筆新的測試資料輸入後，與其最接近的 3筆資料的類別如下：鄰近樣本 1：類別 A；鄰近樣本 2：類別 B；鄰近樣本 3：類別 A。請問模型會將這筆資料預測為哪一類別？",
      "options": [
        { "key": "A", "value": "類別 A" },
        { "key": "B", "value": "類別 B" },
        { "key": "C", "value": "類別 A與 B各一半，無法分類" },
        { "key": "D", "value": "類別 A或 B，視距離遠近加權而定" }
      ],
      "answer": "A",
      "explanation": "KNN 採多數決（Majority Vote）。3 個鄰居中有 2 個 A、1 個 B，因此預測結果為 A。",
      "score": 2,
      "tags": ["KNN", "分類演算法"]
    },
    {
      "id": "q16",
      "type": "single_choice",
      "questionText": "某團隊想採用循環神經網路（Recurrent Neural Network, RNN）建構長期氣候數據的預測模型，以下哪一項敘述最符合使用 RNN 可能會遇到的挑戰？",
      "options": [
        { "key": "A", "value": "RNN無法處理可變長度的序列輸入，因此在實務上限制極大" },
        { "key": "B", "value": "RNN在長序列訓練中可能出現梯度消失，影響模型效果" },
        { "key": "C", "value": "RNN無法捕捉時間上的依賴關係，因此預測準確度低" },
        { "key": "D", "value": "RNN只能用於分類任務，不能應用於時間序列預測" }
      ],
      "answer": "B",
      "explanation": "標準 RNN 在處理長序列時，反向傳播的梯度容易趨近於零（梯度消失），導致模型難以學習長距離的依賴關係。",
      "score": 2,
      "tags": ["深度學習", "RNN"]
    },
    {
      "id": "q17",
      "type": "single_choice",
      "questionText": "一間金融科技公司設計一款智慧投資系統，該系統會根據市場變化自動決定「買進」、「持有」或「賣出」的行動，並根據每次交易後的盈虧結果，逐步優化下一次的投資策略。整個過程中，系統不依賴事先標記的資料，而是根據歷次行動獲得的獎勵進行調整。請問此系統最可能採用哪一種學習方法？",
      "options": [
        { "key": "A", "value": "強化式學習（Reinforcement Learning）" },
        { "key": "B", "value": "監督式學習（Supervised Learning）" },
        { "key": "C", "value": "非監督式學習（Unsupervised Learning）" },
        { "key": "D", "value": "遷移學習（Transfer Learning）" }
      ],
      "answer": "A",
      "explanation": "強化式學習的核心在於透過「行動（Action）」與環境互動，並根據獲得的「獎勵（Reward）」來優化決策策略（Policy），完全符合題目的投資情境。",
      "score": 2,
      "tags": ["強化式學習", "投資策略"]
    },
    {
      "id": "q18",
      "type": "single_choice",
      "questionText": "關於 Q-Learning 與 Deep Q-Learning，下列敘述何者最正確？",
      "options": [
        { "key": "A", "value": "Q-Learning 與 Deep Q-Learning 的差異在於是否使用標記資料作為學習基礎" },
        { "key": "B", "value": "Q-Learning 可處理任意維度的狀態空間，因此比 Deep Q-Learning 更靈活" },
        { "key": "C", "value": "Deep Q-Learning 透過深度神經網路近似 Q值，避免了 Q表在高維空間中難以擴展的問題" },
        { "key": "D", "value": "Deep Q-Learning 無法搭配經驗回放（Experience Replay），因為會導致樣本順序被打亂" }
      ],
      "answer": "C",
      "explanation": "傳統 Q-Learning 使用表格儲存 Q 值，難以處理高維度狀態。Deep Q-Learning (DQN) 引入神經網路來近似 Q 函數，解決了狀態空間過大的問題。",
      "score": 2,
      "tags": ["強化式學習", "DQN"]
    },
    {
      "id": "q19",
      "type": "single_choice",
      "questionText": "在訓練機器學習模型時，若任務為預測房價，應選用下列哪一種損失函數（Loss Function）來衡量預測誤差？",
      "options": [
        { "key": "A", "value": "均方誤差（MSE）" },
        { "key": "B", "value": "交叉熵損失（Cross-Entropy Loss）" },
        { "key": "C", "value": "Hinge損失（Hinge Loss）" },
        { "key": "D", "value": "KL散度（Kullback-Leibler Divergence）" }
      ],
      "answer": "A",
      "explanation": "預測房價屬於「迴歸（Regression）」問題，均方誤差（MSE）是迴歸任務中最常用的損失函數。交叉熵用於分類。",
      "score": 2,
      "tags": ["損失函數", "迴歸"]
    },
    {
      "id": "q20",
      "type": "single_choice",
      "questionText": "某醫院希望開發一個系統，根據患者的年齡、血壓與 BMI等資訊，預測其罹患糖尿病的機率（0~1），並依據預測值是否超過 0.5 做出風險警示。下列哪一種模型最適合用於此分類任務？",
      "options": [
        { "key": "A", "value": "邏輯迴歸（Logistic Regression）" },
        { "key": "B", "value": "支援向量機（Support Vector Machine）" },
        { "key": "C", "value": "決策樹（Decision Tree）" },
        { "key": "D", "value": "K平均演算法（K-means）" }
      ],
      "answer": "A",
      "explanation": "邏輯迴歸雖然名稱有「迴歸」，但它是經典的二元分類模型，能輸出事件發生的機率（0到1之間），非常適合風險評估。",
      "score": 2,
      "tags": ["分類模型", "邏輯迴歸"]
    },
    {
      "id": "q21",
      "type": "single_choice",
      "questionText": "某金融科技公司正開發一套違約風險預測系統，需大量處理不同客戶的財務特徵資料。考量到資料特徵數量眾多，且希望提升預測的穩定性與泛化能力，下列哪一種鑑別式 AI模型最適合？",
      "options": [
        { "key": "A", "value": "邏輯迴歸（Logistic Regression）" },
        { "key": "B", "value": "支援向量機（Support Vector Machine）" },
        { "key": "C", "value": "決策樹（Decision Tree）" },
        { "key": "D", "value": "隨機森林（Random Forest）" }
      ],
      "answer": "D",
      "explanation": "隨機森林是基於決策樹的集成學習方法，能有效處理高維度特徵，且透過集成多棵樹的結果，比單一決策樹更穩定、泛化能力更好，不易過度擬合。",
      "score": 2,
      "tags": ["集成學習", "隨機森林"]
    },
    {
      "id": "q22",
      "type": "single_choice",
      "questionText": "關於變分自編碼器（Variational Autoencoder, VAE）的運作流程，下列何者敘述最為正確？",
      "options": [
        { "key": "A", "value": "解碼器的任務是將低維壓縮向量分類為不同類別" },
        { "key": "B", "value": "編碼器將輸入資料轉換為可視化圖像以利模型學習" },
        { "key": "C", "value": "編碼器將資料轉換為潛在空間表示，解碼器再重建資料" },
        { "key": "D", "value": "編碼器利用最大邊際機率對資料進行異常點偵測" }
      ],
      "answer": "C",
      "explanation": "VAE 的架構包含編碼器（Encoder）與解碼器（Decoder）。編碼器將輸入映射到潛在空間（Latent Space）的分佈，解碼器則從該空間採樣並重建原始資料。",
      "score": 2,
      "tags": ["深度學習", "VAE"]
    },
    {
      "id": "q23",
      "type": "single_choice",
      "questionText": "下列何者不是我國數位發展部 AI 產品與系統評測中心對生成式 AI 的評測項目?",
      "options": [
        { "key": "A", "value": "當責性" },
        { "key": "B", "value": "可靠性" },
        { "key": "C", "value": "隱私及資安" },
        { "key": "D", "value": "互動性" }
      ],
      "answer": "D",
      "explanation": "AI 產品評測主要關注安全性、準確性與倫理風險。當責性、可靠性、隱私及資安皆為核心指標，而「互動性」屬於使用者體驗範疇，非主要安全評測項目。",
      "score": 2,
      "tags": ["AI評測", "安全性"]
    },
    {
      "id": "q24",
      "type": "single_choice",
      "questionText": "在保持 GPT-OSS模型架構不變的前提下，如果將模型參數量從 20億提升至 120億，並假設有足夠的訓練資料支撐，下列敘述何者最正確？",
      "options": [
        { "key": "A", "value": "模型參數增加會線性提升效能，且即使訓練資料不變也不會遇到瓶頸" },
        { "key": "B", "value": "參數越多模型推理越快，因為每層可以並行計算更多參數" },
        { "key": "C", "value": "較大的參數量能提升模型的表達能力與預測效能，但需足夠訓練資料支持" },
        { "key": "D", "value": "增加參數量不影響記憶體使用，只會影響計算速度" }
      ],
      "answer": "C",
      "explanation": "根據 Scaling Law，增加模型參數通常能提升效能，但前提是有相對應足夠數量的訓練資料。參數量增加會增加記憶體消耗並降低推理速度。",
      "score": 2,
      "tags": ["大型語言模型", "Scaling Law"]
    },
    {
      "id": "q25",
      "type": "single_choice",
      "questionText": "在自然語言處理任務中，為了減少訓練語料中偏見對模型的影響，下列哪種資料處理策略屬於常見的「資料去偏（Data Debiasing）」做法？",
      "options": [
        { "key": "A", "value": "讓模型在訓練時隨機替換輸出，以抵消資料中存在的系統性偏差" },
        { "key": "B", "value": "增加模型的參數量，依賴更大的模型自動消除原始資料中的偏見" },
        { "key": "C", "value": "調整或擴充訓練語料，使不同群體或類型資料的比例更加平衡，避免模型過度偏向出現頻率高的類別" },
        { "key": "D", "value": "對訓練資料施加額外正則化或噪音，使模型在學習過程中對偏見敏感度降低" }
      ],
      "answer": "C",
      "explanation": "資料去偏最直接有效的方法是處理數據本身，例如透過重採樣（Resampling）或數據增強（Augmentation）來平衡不同群體的代表性，減少因數據不均導致的偏見。",
      "score": 2,
      "tags": ["NLP", "資料去偏"]
    },
    {
      "id": "q26",
      "type": "single_choice",
      "questionText": "在深度學習模型的微調（Fine-tuning）過程中，可能出現所謂的「災難性遺忘（Catastrophic Forgetting）」。此現象最可能造成哪種情況？",
      "options": [
        { "key": "A", "value": "由於計算資源或訓練步驟不足，模型在微調過程中無法完整收斂，導致學習效果受限" },
        { "key": "B", "value": "微調後模型的表現變得隨機，無法有效記憶新學到的模式與知識" },
        { "key": "C", "value": "微調後模型的部分權重產生偏移，導致模型無法針對較長的文字進行回應" },
        { "key": "D", "value": "模型過度適應微調的資料分佈，逐漸遺忘先前預訓練所獲得的廣泛知識，在原有任務或廣泛領域上表現變差" }
      ],
      "answer": "D",
      "explanation": "災難性遺忘是指神經網路在學習新任務時，覆蓋了舊任務的權重配置，導致舊任務（或通用能力）的表現大幅下降。",
      "score": 2,
      "tags": ["微調", "災難性遺忘"]
    },
    {
      "id": "q27",
      "type": "single_choice",
      "questionText": "在大型 Transformer 模型的效能優化過程中，常見的方法之一是「剪枝（Pruning）」。下列哪一項最符合該方法的核心概念？",
      "options": [
        { "key": "A", "value": "將模型中所有權重按比例縮小，使其值更接近零，以降低計算量" },
        { "key": "B", "value": "移除模型中影響較小或冗餘的部分權重參數，以減少模型大小並提升推理效率" },
        { "key": "C", "value": "在訓練時僅更新部分權重而將其他權重凍結，從而減少需要調整的參數數量" },
        { "key": "D", "value": "根據注意力分數動態跳過處理部分輸入 Token，以減少每次前向傳播的計算" }
      ],
      "answer": "B",
      "explanation": "剪枝（Pruning）是透過移除神經網路中不重要的連接或神經元（權重），來簡化模型結構，達到壓縮模型體積與加速推論的目的。",
      "score": 2,
      "tags": ["模型優化", "剪枝"]
    },
    {
      "id": "q28",
      "type": "single_choice",
      "questionText": "對非常長的輸入序列進行推理（Inference），Transformer模型推理的主要計算瓶頸通常是什麼？",
      "options": [
        { "key": "A", "value": "模型輸出層產生文本的過程，因為每生成一個詞都必須重新訓練整個模型一次" },
        { "key": "B", "value": "詞嵌入 (Embedding) 查找操作，因為其時間複雜度隨詞彙表大小指數級增長" },
        { "key": "C", "value": "Softmax 函數的計算，因為對每個 Token都需要執行繁重的運算" },
        { "key": "D", "value": "自注意力層的計算和其記憶體使用，因為注意力矩陣的大小隨序列長度呈平方級增長" }
      ],
      "answer": "D",
      "explanation": "Transformer 的自注意力機制（Self-Attention）計算複雜度與序列長度的平方成正比（$O(N^2)$），因此處理長序列時，記憶體與計算量會急劇增加。",
      "score": 2,
      "tags": ["Transformer", "Attention機制"]
    },
    {
      "id": "q29",
      "type": "single_choice",
      "questionText": "在「可解釋人工智慧（Explainable AI, XAI）」領域中，LIME（Local Interpretable Model-agnostic Explanations）方法最核心的應用目的是什麼？",
      "options": [
        { "key": "A", "value": "解釋單一樣本（局部預測）的黑箱模型決策過程" },
        { "key": "B", "value": "全面提升黑箱模型整體的預測準確度" },
        { "key": "C", "value": "將黑箱模型轉換成完全可解釋的模型作為替代" },
        { "key": "D", "value": "用於生成大量擬真數據來替代訓練集" }
      ],
      "answer": "A",
      "explanation": "LIME 的核心是「局部（Local）」解釋。它在單一預測樣本附近進行擾動與採樣，訓練一個簡單的可解釋模型（如線性模型）來近似黑箱模型在該局部的行為。",
      "score": 2,
      "tags": ["XAI", "LIME"]
    },
    {
      "id": "q30",
      "type": "single_choice",
      "questionText": "在醫療診斷決策支援系統等高風險領域中，「可解釋人工智慧（Explainable AI, XAI）」的核心價值最主要呈現在哪個面向？",
      "options": [
        { "key": "A", "value": "透過提供可理解的決策依據，促進患者與醫療專業人員對系統診斷結果的信任與接受度" },
        { "key": "B", "value": "以可解釋性方法優化臨床資料蒐集與管理流程，從而降低整體醫療作業成本" },
        { "key": "C", "value": "利用解釋機制增強模型預測的統計顯著性與準確度，使其在研究及實務應用中更具科學性" },
        { "key": "D", "value": "透過提供透明化的運作過程，進而減輕臨床人員負擔，並提升醫療服務的整體效率" }
      ],
      "answer": "A",
      "explanation": "在醫療領域，信任至關重要。XAI 提供判斷依據（例如標出 X 光片上的病徵位置），讓醫生能驗證 AI 的建議，從而建立人機協作的信任感。",
      "score": 2,
      "tags": ["XAI", "醫療AI"]
    },
    {
      "id": "q31",
      "type": "single_choice",
      "questionText": "在金融科技公司的信貸決策系統中，導入反事實解釋（Counterfactual Explanation）時，實際部署往往伴隨技術與監管挑戰。下列哪一項最符合該情境下的核心挑戰？",
      "options": [
        { "key": "A", "value": "需要建立完整的客戶行為預測模型來估算建議改變的實施成本，並整合到現有的風險管理系統架構中" },
        { "key": "B", "value": "必須使用聯邦學習技術保護客戶隱私，同時在分散式環境中計算跨機構的反事實解釋結果" },
        { "key": "C", "value": "需要建構時間序列因果圖來處理客戶信用狀況的動態變化，並預測未來可能的信用評分軌跡" },
        { "key": "D", "value": "生成的反事實樣本必須滿足特徵間的因果約束和業務邏輯約束，同時確保建議的改變在現實中具有可操作性且符合公平放貸法規" }
      ],
      "answer": "D",
      "explanation": "反事實解釋（例如：「如果你月薪增加 5000 元就能獲貸」）必須是「可行的」且「合邏輯的」。如果系統建議客戶「變更年齡」或「減少工齡」，則是無效且不合規的解釋。",
      "score": 2,
      "tags": ["XAI", "反事實解釋"]
    },
    {
      "id": "q32",
      "type": "single_choice",
      "questionText": "在統計推論中，若樣本來自母體但呈現明顯偏態分布，且樣本數有限，下列哪一項策略最能減少推估母體參數的偏誤？",
      "options": [
        { "key": "A", "value": "直接使用樣本平均數與變異數估計母體參數，不做任何調整" },
        { "key": "B", "value": "增加樣本數並考慮使用分位數或中位數作為中心趨勢估計" },
        { "key": "C", "value": "將樣本隨機重新排列後，多次計算平均值以消除偏態影響" },
        { "key": "D", "value": "完全依賴樣本標準差來估計母體參數，忽略分布形態" }
      ],
      "answer": "B",
      "explanation": "在偏態分佈中，平均數容易受極端值影響。中位數（Median）或分位數是更穩健（Robust）的中心趨勢指標，能減少推論偏誤。",
      "score": 2,
      "tags": ["統計學", "偏態分布"]
    },
    {
      "id": "q33",
      "type": "single_choice",
      "questionText": "在工業物聯網架構中，進行設備預測性維護（Predictive Maintenance）時，若面對異常事件發生頻率極低、樣本高度不平衡的時間序列資料，下列哪一種方法最能兼顧模型穩定性與異常偵測效能？",
      "options": [
        { "key": "A", "value": "將每筆異常事件資料複製多次以提升模型對異常的辨識敏感度，搭配全序列訓練模型（如 LSTM）" },
        { "key": "B", "value": "對時間序列進行差分與標準化後，使用傳統監督式學習模型（如 SVM）進行分類訓練" },
        { "key": "C", "value": "使用經過時間序列特化的 SMOTE技術生成異常樣本，以平衡異常與正常資料比例" },
        { "key": "D", "value": "採用基於重建誤差的自編碼器模型（ Sequence-to-Sequence Autoencoder）進行異常偵測，並僅使用正常資料進行訓練" }
      ],
      "answer": "D",
      "explanation": "對於極度不平衡的資料，使用僅以正常資料訓練的自編碼器（Autoencoder）是常見策略。模型學會重建正常訊號，當異常發生時，重建誤差（Reconstruction Error）會顯著升高，藉此偵測異常。",
      "score": 2,
      "tags": ["異常偵測", "預測性維護"]
    },
    {
      "id": "q34",
      "type": "single_choice",
      "questionText": "在零售業進行客戶行為分析時，資料倉儲中發現多個欄位儲存相同的購買金額資訊（例如：amount_usd、total_price、transaction_value），但其單位、命名慣例及格式不一致，進而導致特徵工程階段混淆模型輸入。針對此種跨欄位語義重疊與結構冗餘問題，下列哪一種資料處理策略最合適且具實務可行性？",
      "options": [
        { "key": "A", "value": "利用資料探勘技術自動選擇資料集中對目標變數最敏感的欄位，其他欄位捨棄即可，避免過度清理干擾原始結構" },
        { "key": "B", "value": "保留所有相似欄位，交由高階模型（如 Gradient Boosting或 Deep Learning）自動學習特徵關聯，無需手動處理" },
        { "key": "C", "value": "建立欄位命名標準，統一金額單位與格式，進行欄位正規化與語義合併，減少重複資訊影響特徵重要性估計" },
        { "key": "D", "value": "將重複欄位視為類別欄位，進行 One-hot編碼（One-hot encoding）後輸入模型，以避免數值誤導模型學習過程" }
      ],
      "answer": "C",
      "explanation": "資料清理是模型成功的關鍵。面對語義重複且格式混亂的欄位，正確做法是進行標準化（Standardization）與合併（Merging），以提供乾淨且具代表性的特徵給模型。",
      "score": 2,
      "tags": ["資料清理", "特徵工程"]
    },
    {
      "id": "q35",
      "type": "single_choice",
      "questionText": "某大型零售企業準備將商品推薦模型上線，專案團隊在檢視訓練資料時，發現部分商品類別（例如高價商品）樣本數量極少，而多數樣本集中於低價商品。若此不平衡問題未妥善處理，下列何種狀況最可能在實際推薦結果中發生？",
      "options": [
        { "key": "A", "value": "模型在預測時傾向輸出稀有類別，導致雖能捕捉到少數樣本，但精確率（Precision）顯著下降" },
        { "key": "B", "value": "模型由於類別分布不均，難以建立有效的線性分離邊界，進而無法收斂" },
        { "key": "C", "value": "模型過度聚焦於稀有類別樣本，導致對多數類別的預測能力下降，整體效能受損" },
        { "key": "D", "value": "模型學到的決策邊界主要由多數類別主導，忽視了稀有類別，造成該類別的召回率（Recall）大幅降低" }
      ],
      "answer": "D",
      "explanation": "在資料不平衡的情況下，模型為了最小化整體誤差，傾向於預測多數類別，導致對少數類別（稀有商品）的偵測能力（召回率 Recall）變差。",
      "score": 2,
      "tags": ["資料不平衡", "推薦系統"]
    },
    {
      "id": "q36",
      "type": "single_choice",
      "questionText": "某電商資料團隊要協助行銷部門規劃再行銷策略。目前取得資料包含使用者點擊、購買紀錄、流量來源與轉換率。若資料團隊希望先進行探索性資料分析（EDA），下列哪一項最符合 EDA的做法？",
      "options": [
        { "key": "A", "value": "建立隨機森林模型，預測使用者是否會完成購買" },
        { "key": "B", "value": "使用 K-means對使用者群進行分群並立即制定對應促銷策略" },
        { "key": "C", "value": "繪製各類流量來源對轉換率的關聯圖，尋找潛在關係" },
        { "key": "D", "value": "對不同購物路徑設定統計假設並進行雙樣本 t檢定" }
      ],
      "answer": "C",
      "explanation": "探索性資料分析（EDA）旨在透過視覺化（如關聯圖、散佈圖）來理解資料特徵與變數間的關係，而非建立預測模型（A、B）或進行假設檢定（D）。",
      "score": 2,
      "tags": ["EDA", "探索性資料分析"]
    },
    {
      "id": "q37",
      "type": "single_choice",
      "questionText": "某金融科技公司在利用歷史交易資料建立風險控管模型時，嘗試推估整體詐騙交易比例。近期發現，樣本間存在明顯的時間序列相關性，導致模型在實際偵測新交易時誤判率升高。若希望同時改善詐騙比例推估的準確性並提升模型的穩健性，下列哪一種做法最為合適？",
      "options": [
        { "key": "A", "value": "擴充樣本數量，以涵蓋更多潛在的詐騙型態，但維持既有的隨機抽樣方式不變" },
        { "key": "B", "value": "採取時間序列敏感的抽樣策略，例如依據交易時間區間進行分層，以保存原始的時間結構特性" },
        { "key": "C", "value": "將資料完全隨機打散，以降低序列相關性對模型訓練造成的影響" },
        { "key": "D", "value": "在模型評估時，針對相鄰時間區段進行誤差合併，以便用整體估計方式修正詐騙比例" }
      ],
      "answer": "B",
      "explanation": "對於時間序列資料（如交易紀錄），隨機抽樣會破壞時間相依性。正確做法是依時間分層或使用時間序列交叉驗證（Time Series Cross-Validation），以確保模型能泛化到未來數據。",
      "score": 2,
      "tags": ["時間序列", "抽樣策略"]
    },
    {
      "id": "q38",
      "type": "single_choice",
      "questionText": "某公司建置基於檢索增強生成（RAG）的知識查詢系統，需同時兼顧查詢效能與資料的即時更新。近期發現回應內容偶爾過時，且每次更新文件都需完整重建索引，導致系統在更新期間無法服務。若要解決此問題並提升整體穩健性，下列哪項做法最適合？",
      "options": [
        { "key": "A", "value": "調整生成模型的回應隨機性參數，以降低答案偏差並提升一致性" },
        { "key": "B", "value": "提升檢索與索引的運算效能，以縮短查詢與更新所需時間" },
        { "key": "C", "value": "採用索引的增量或分段更新方式，使新資料能即時納入而不需全部重建" },
        { "key": "D", "value": "建立常見問題的標準答案集，透過快速檢索回應以降低模型負擔" }
      ],
      "answer": "C",
      "explanation": "增量更新（Incremental Indexing）允許系統僅處理新增或變更的文件，而無需重建整個向量索引，這能顯著降低更新成本並提升資料的新鮮度（Freshness）。",
      "score": 2,
      "tags": ["RAG", "系統架構"]
    },
    {
      "id": "q39",
      "type": "single_choice",
      "questionText": "某醫院計畫開發住院日數預測模型，以協助病房調度。多數病人的住院日數集中在 3–7天，但仍有少數重症患者因治療需求而住院日數明顯偏長。醫院希望採用一種合適的評估方式，既能兼顧大部分病人的預測準確度，也能確保對重症個案的預測維持穩健。下列哪一種方法最符合此需求？",
      "options": [
        { "key": "A", "value": "在模型檢核時，同時呈現平均絕對誤差（MAE）與重症子群的誤差指標" },
        { "key": "B", "value": "僅針對一般病人樣本進行交叉驗證，以避免重症個案拉高誤差" },
        { "key": "C", "value": "將所有病人的住院日數進行標準化處理，以減少數值範圍差異的影響" },
        { "key": "D", "value": "只採用單一的整體決定係數 (R²) 作為模型優劣的判斷依據" }
      ],
      "answer": "A",
      "explanation": "全域指標（如 R²）常掩蓋模型在少數關鍵子群（如重症患者）的表現。分群評估（MAE for General vs. Severe）能確保模型在不同風險等級的病人身上都具備可靠性。",
      "score": 2,
      "tags": ["模型評估", "MAE"]
    },
    {
      "id": "q40",
      "type": "single_choice",
      "questionText": "關於監督式學習（Supervised Learning）與非監督式學習（Unsupervised Learning）的目標，下列敘述何者錯誤？\n1.非監督式學習的核心在於發掘資料內在結構，例如分群、關聯規則與降維，而不依賴外部標籤。\n2.監督式學習的典型應用為分類與迴歸，通常不適合應用於異常偵測任務。\n3.非監督式學習若搭配少量標註資料，即會完全轉化為監督式學習。\n4.監督式學習仰賴已標註的資料集，透過最小化輸出與真實標籤之間的差距，學習輸入與目標之間的對應函數。\n5.所有監督式學習任務都必須要有大量完整標註資料，否則無法進行任何有效的模型訓練。\n6.非監督式學習不需要目標變數，僅透過輸入資料本身的特徵分布進行模式學習。",
      "options": [
        { "key": "A", "value": "3、5、6" },
        { "key": "B", "value": "1、4、6" },
        { "key": "C", "value": "2、4、6" },
        { "key": "D", "value": "2、3、5" }
      ],
      "answer": "D",
      "explanation": "錯誤敘述解析：2. 監督式學習（如詐欺偵測）常用於異常偵測。3. 搭配少量標註資料是「半監督學習」，非轉化為監督式。5. 遷移學習或少樣本學習（Few-shot）可在少量資料下運作。",
      "score": 2,
      "tags": ["機器學習概念", "監督式學習"]
    },
    {
      "id": "q41",
      "type": "single_choice",
      "questionText": "一家旅遊平台希望建立模型，預測顧客下次是否會再次透過該平台訂房。資料包含：顧客 ID、年齡、旅遊次數、平均花費金額、主要交通方式（火車/飛機/自駕/公車）、會員等級（普通/進階/白金）、是否為海外旅遊等。下列哪一種特徵工程方法最適合處理「主要交通方式」欄位？",
      "options": [
        { "key": "A", "value": "布林轉換（Boolean Conversion）" },
        { "key": "B", "value": "序數編碼（Ordinal Encoding）" },
        { "key": "C", "value": "數值標準化（Numerical Standardization）" },
        { "key": "D", "value": "One-hot 編碼（One-hot Encoding）" }
      ],
      "answer": "D",
      "explanation": "「交通方式」是名目變數（Nominal），沒有順序關係（火車不一定大於公車）。One-hot Encoding 是處理此類類別特徵的標準方法。",
      "score": 2,
      "tags": ["特徵工程", "One-hot Encoding"]
    },
    {
      "id": "q42",
      "type": "single_choice",
      "questionText": "一家跨國醫療研究機構希望利用各地醫院的病患資料，建立一個能夠預測疾病早期風險的機器學習模型。由於各國法規限制，病患的原始資料無法集中到單一伺服器。在此情境下，下列哪一種方法最能同時滿足「各醫院保留資料不外流」與「模型仍能跨院學習」的需求？",
      "options": [
        { "key": "A", "value": "資料匿名化（Data Anonymization）" },
        { "key": "B", "value": "差分隱私（Differential Privacy）" },
        { "key": "C", "value": "聯邦學習（Federated Learning）" },
        { "key": "D", "value": "交叉驗證（Cross-validation）" }
      ],
      "answer": "C",
      "explanation": "聯邦學習（Federated Learning）允許模型在本地訓練，僅上傳參數更新（Gradient/Weight）至中央伺服器，原始數據無需離開本地，完美解決資料主權與隱私問題。",
      "score": 2,
      "tags": ["隱私保護", "聯邦學習"]
    },
    {
      "id": "q43",
      "type": "single_choice",
      "questionText": "某公司欲建立員工離職風險預測模型，資料集中包含「年度績效分數」、「平均每月加班時數」、「年齡」等數值型特徵。由於各特徵的數值範圍差異極大（例如績效分數 1–5、加班時數 0–80、年齡 20–65），若直接輸入至使用梯度下降的邏輯迴歸(Logistic Regression)模型，可能導致模型收斂緩慢或權重偏斜。為提升模型訓練效率與準確度，下列哪一種特徵工程方法最適合應用於這些數值特徵？",
      "options": [
        { "key": "A", "value": "布林轉換（Boolean Conversion）" },
        { "key": "B", "value": "時間序列分解（Time Series Decomposition）" },
        { "key": "C", "value": "One-hot 編碼（One-hot Encoding）" },
        { "key": "D", "value": "數值標準化（Numerical Standardization）" }
      ],
      "answer": "D",
      "explanation": "邏輯迴歸等依賴梯度下降的模型對特徵尺度非常敏感。數值標準化（Normalization/Standardization）能將不同範圍的特徵縮放到相同尺度，加速收斂並提升效能。",
      "score": 2,
      "tags": ["特徵工程", "標準化"]
    },
    {
      "id": "q44",
      "type": "single_choice",
      "questionText": "在機器學習中，「叢集（Clustering）」方法最典型的應用情境是下列何者？",
      "options": [
        { "key": "A", "value": "根據歷史交易紀錄與已標註的詐欺案例，訓練模型來偵測未來的詐欺交易" },
        { "key": "B", "value": "使用醫療數據與病患的診斷標籤，建立模型以預測病人是否罹患特定疾病" },
        { "key": "C", "value": "根據顧客的消費行為與特徵，將顧客自動劃分為數個群組，以便進行差異化行銷" },
        { "key": "D", "value": "透過大量已標註影像，訓練深度學習模型來辨識照片中的物件種類" }
      ],
      "answer": "C",
      "explanation": "叢集（Clustering）屬於非監督式學習，不需要標籤。選項 C 的「顧客分群」是利用特徵相似性將資料分組，是叢集的經典應用。",
      "score": 2,
      "tags": ["分群", "Clustering"]
    },
    {
      "id": "q45",
      "type": "single_choice",
      "questionText": "某醫院研究團隊蒐集了大量病患的「收縮壓」數據，經檢驗後顯示此數值大致呈現常態分布。在進行後續模型分析前，研究人員希望妥善處理可能存在的極端血壓數值。下列哪一種做法最為合適？",
      "options": [
        { "key": "A", "value": "將所有極端偏高或偏低的血壓數據直接刪除，以保留最具代表性的病患樣本" },
        { "key": "B", "value": "使用對數轉換（Log Transformation），將數據壓縮至更接近常態，以降低極端值的影響" },
        { "key": "C", "value": "透過 Z分數（Z-score）或標準差範圍檢測異常值，並依研究需求決定是否調整或移除" },
        { "key": "D", "value": "將檢測到的離群值以 Label Encoding 編碼，轉換為序號標籤以避免影響原始分布" }
      ],
      "answer": "C",
      "explanation": "對於常態分佈數據，使用 Z-score（例如超過 3 個標準差）是檢測異常值的標準統計方法。直接刪除（A）可能損失重要資訊，應先檢測再決定策略。",
      "score": 2,
      "tags": ["異常值處理", "統計學"]
    },
    {
      "id": "q46",
      "type": "single_choice",
      "questionText": "某電商公司想預測用戶是否會購買特定商品，資料中包含多種用戶屬性與行為特徵。分析師希望選出對購買結果最有預測價值的特徵，以提升模型效能。下列哪一種描述最符合監督式特徵選擇（Supervised Feature Selection）的概念？",
      "options": [
        { "key": "A", "value": "根據特徵的整體分布、變異度或資訊量進行篩選，而不直接參考目標變數" },
        { "key": "B", "value": "評估每個特徵與目標變數之間的相關性，選擇對預測結果貢獻最大的特徵" },
        { "key": "C", "value": "使用模型評估特徵對預測結果的重要性，並保留對目標變數影響較大的欄位" },
        { "key": "D", "value": "將特徵透過降維方法（如 PCA）轉換為新特徵，再用於模型訓練" }
      ],
      "answer": "B",
      "explanation": "監督式特徵選擇會利用目標變數（Target）來評估特徵的重要性，例如計算特徵與目標的相關係數或互信息（Mutual Information）。",
      "score": 2,
      "tags": ["特徵選擇", "監督式學習"]
    },
    {
      "id": "q47",
      "type": "single_choice",
      "questionText": "在訓練神經網路時，為了提升模型收斂速度與穩定性，避免梯度消失或梯度爆炸，下列哪一種做法最常被使用？",
      "options": [
        { "key": "A", "value": "對輸入資料進行隨機旋轉或水平翻轉，以增加資料多樣性" },
        { "key": "B", "value": "選用 ReLU 或其變體作為隱藏層的啟動函數，以改善梯度傳播" },
        { "key": "C", "value": "減少樣本量提升訓練速度" },
        { "key": "D", "value": "對目標變數或特徵進行標準化" }
      ],
      "answer": "B",
      "explanation": "ReLU（Rectified Linear Unit）函數在正區間的梯度恆為 1，有效解決了 Sigmoid 或 Tanh 函數在深層網路中容易發生的梯度消失問題。",
      "score": 2,
      "tags": ["神經網路", "啟動函數"]
    },
    {
      "id": "q48",
      "type": "single_choice",
      "questionText": "若希望檢視某一連續型數據的分布情形（如集中程度、偏態或是否呈現多峰），下列哪一種應用情境最適合使用直方圖（Histogram） 來進行分析？",
      "options": [
        { "key": "A", "value": "探討顧客年齡資料的整體分布特徵，並檢視是否存在異常集中或分散現象" },
        { "key": "B", "value": "比較不同商品在各月份的銷售額變化趨勢，以觀察季節性波動" },
        { "key": "C", "value": "追蹤公司近一年營收的時間序列變化，以了解整體成長趨勢" },
        { "key": "D", "value": "檢視產品價格與月銷售量之間的關聯性，以評估是否具線性相關" }
      ],
      "answer": "A",
      "explanation": "直方圖（Histogram）專門用於呈現單一連續變數的頻率分佈，能清楚顯示數據的集中趨勢、偏態與峰度。B、C 適合折線圖，D 適合散佈圖。",
      "score": 2,
      "tags": ["資料視覺化", "直方圖"]
    },
    {
      "id": "q49",
      "type": "single_choice",
      "questionText": "下列何者並非我國數位發展部 AI 產品與評測中心在評估大型語言模型安全性時，所指出的常見使用指標？",
      "options": [
        { "key": "A", "value": "資料複雜性" },
        { "key": "B", "value": "事實正確性" },
        { "key": "C", "value": "偏見與歧視" },
        { "key": "D", "value": "惡意與濫用可能性" }
      ],
      "answer": "A",
      "explanation": "安全性評測主要針對模型的輸出風險（如偏見、幻覺、惡意內容）。「資料複雜性」通常屬於資料品質或工程特徵，非直接的安全性評測指標。",
      "score": 2,
      "tags": ["AI評測", "安全性"]
    },
    {
      "id": "q50",
      "type": "single_choice",
      "questionText": "某雲端服務公司計畫將大型語言模型部署於線上系統，並以批次推論（Batch Inference）方式處理每日上百萬筆用戶請求。專案團隊在評估可能遇到的挑戰時，下列哪一項通常不會被視為批次推論階段的主要難題？",
      "options": [
        { "key": "A", "value": "如何確保訓練語料的涵蓋性與標註品質，以避免模型偏差影響輸出" },
        { "key": "B", "value": "當批次規模增大時，如何降低推論延遲並保持即時回應能力" },
        { "key": "C", "value": "在推論過程中，有效管理與分配龐大的輸入資料量以避免資源壅塞" },
        { "key": "D", "value": "在叢集環境中精確安排推論任務，以提升 GPU/TPU等硬體資源的利用率" }
      ],
      "answer": "A",
      "explanation": "選項 A 屬於「模型訓練（Training）」階段的問題。批次推論（Inference）階段關注的是系統效能、延遲（Latency）、吞吐量（Throughput）與資源管理。",
      "score": 2,
      "tags": ["MLOps", "批次推論"]
    }
  ]
}
