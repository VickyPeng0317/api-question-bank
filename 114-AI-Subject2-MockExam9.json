{
  "level": "junior",
  "type": "生成式AI應用與規劃",
  "quiz_id": "114-AI-Subject2-MockExam9",
  "title": "114年初級AI應用規劃師第二科：生成式AI應用與規劃 (模擬考卷九)",
  "exam_date": "2025-11-01",
  "questions": [
    {
      "id": "q1",
      "type": "single_choice",
      "questionText": "「提供直觀的圖形化界面和拖放工具，使用者無需編寫程式碼即可開發應用程式」，這段描述最符合下列哪一種平台的特性？",
      "options": [
        { "key": "A", "value": "High Code 平台" },
        { "key": "B", "value": "Low Code 平台" },
        { "key": "C", "value": "No Code 平台" },
        { "key": "D", "value": "開源演算法資料庫" }
      ],
      "answer": "C",
      "explanation": "No Code 平台主要面向非技術使用者，允許透過直觀的拖放介面構建應用程式，無需撰寫任何程式碼，適用於快速原型設計。[1-3]",
      "score": 2,
      "tags": ["No code / Low code", "基本概念"]
    },
    {
      "id": "q2",
      "type": "single_choice",
      "questionText": "與 No Code 平台相比，Low Code 平台具備什麼樣的獨特優勢，使其更適合中大型企業？",
      "options": [
        { "key": "A", "value": "完全不需要任何程式設計基礎" },
        { "key": "B", "value": "允許技術人員編寫少量程式碼以實現深度整合、高度客製化與複雜邏輯" },
        { "key": "C", "value": "僅能建立靜態的文字網頁" },
        { "key": "D", "value": "完全杜絕了資料外洩的風險" }
      ],
      "answer": "B",
      "explanation": "Low Code 平台結合了視覺化開發工具與程式碼擴充功能，允許技術人員編寫少量程式碼，以滿足中大型企業對複雜邏輯與系統深度整合的需求。[3, 4]",
      "score": 2,
      "tags": ["No code / Low code", "Low Code優勢"]
    },
    {
      "id": "q3",
      "type": "single_choice",
      "questionText": "「AI 民主化 (AI Democratization)」的核心理念為何？",
      "options": [
        { "key": "A", "value": "將 AI 系統完全開源，供任何企業免費進行商業販售" },
        { "key": "B", "value": "透過降低技術門檻，讓非技術背景人士與中小企業也能參與 AI 開發並受益" },
        { "key": "C", "value": "利用 AI 取代各國傳統的投票系統" },
        { "key": "D", "value": "限制大型科技公司研發 AI，將資源強制分配給新創企業" }
      ],
      "answer": "B",
      "explanation": "AI 民主化旨在降低 AI 的技術門檻，將 AI 的使用擴展到更廣泛的社會層面，讓更多非技術背景的人士和中小型企業都能參與 AI 開發並創造價值。[5, 6]",
      "score": 2,
      "tags": ["AI民主化", "核心理念"]
    },
    {
      "id": "q4",
      "type": "single_choice",
      "questionText": "非技術背景的員工，能利用 No Code / Low Code 平台工具自行開發自動化流程（如報告生成與數據輸入）以提升生產力。這類員工在業界常被稱為什麼？",
      "options": [
        { "key": "A", "value": "全端工程師 (Full-stack Developer)" },
        { "key": "B", "value": "市民開發者 (Citizen Developer)" },
        { "key": "C", "value": "資料科學家 (Data Scientist)" },
        { "key": "D", "value": "系統架構師 (System Architect)" }
      ],
      "answer": "B",
      "explanation": "No Code / Low Code 平台將技術力量擴展到非技術背景的人員，他們能自行開發自動化應用，被稱為「市民開發者 (Citizen Developer)」。[6]",
      "score": 2,
      "tags": ["No code / Low code", "市民開發者"]
    },
    {
      "id": "q5",
      "type": "single_choice",
      "questionText": "在評估導入 No Code / Low Code 平台時，企業必須衡量該平台的「總擁有成本 (Total Cost of Ownership, TCO)」。下列何者屬於 TCO 的評估範疇？",
      "options": [
        { "key": "A", "value": "僅包含軟體的初始購買授權費用" },
        { "key": "B", "value": "僅計算硬體設備的採購費用" },
        { "key": "C", "value": "包含平台的購買、長期維護、員工培訓等直接與隱性相關成本" },
        { "key": "D", "value": "平台幫助企業提升的總營收" }
      ],
      "answer": "C",
      "explanation": "總擁有成本 (TCO) 考量的不僅是初期的購買費用，還必須全面包含後續的系統維護、系統整合、員工培訓等所有相關的直接與隱性費用。[7]",
      "score": 2,
      "tags": ["導入評估", "TCO"]
    },
    {
      "id": "q6",
      "type": "single_choice",
      "questionText": "生成式 AI 在「醫療保健」領域最典型的應用場景之一為何？",
      "options": [
        { "key": "A", "value": "自動生成高頻交易演算法" },
        { "key": "B", "value": "預測潛在藥物分子結構以協助新藥開發，縮短研發週期" },
        { "key": "C", "value": "優化製造業的供應鏈與庫存成本" },
        { "key": "D", "value": "生成遊戲中的 3D 動畫場景" }
      ],
      "answer": "B",
      "explanation": "在醫療領域，生成式 AI 可分析大量生物醫學數據，預測分子結構，協助新藥開發與設計，從而顯著縮短研發週期。[8, 9]",
      "score": 2,
      "tags": ["產業應用", "醫療保健"]
    },
    {
      "id": "q7",
      "type": "single_choice",
      "questionText": "生成式 AI 在「金融業」中最具價值的應用情境為何？",
      "options": [
        { "key": "A", "value": "撰寫並生成電子病歷" },
        { "key": "B", "value": "生成產品設計的 3D 原型" },
        { "key": "C", "value": "模擬市場情境進行風險評估與投資組合優化，並自動化合規監管" },
        { "key": "D", "value": "優化工廠的自動化生產線" }
      ],
      "answer": "C",
      "explanation": "金融業中，生成式 AI 可模擬各種市場情境以協助風險評估，並結合市場數據提供最佳投資組合建議，以及透過自動化監控協助合規監管。[8, 10]",
      "score": 2,
      "tags": ["產業應用", "金融業"]
    },
    {
      "id": "q8",
      "type": "single_choice",
      "questionText": "在文本數據進入深度學習模型訓練前，必須先將文本「拆分為基本單元（如詞或子詞）」，以便模型處理。這個前置處理步驟稱為？",
      "options": [
        { "key": "A", "value": "向量化表示 (Vectorization)" },
        { "key": "B", "value": "標記化處理 (Tokenization)" },
        { "key": "C", "value": "數據清洗 (Data Cleaning)" },
        { "key": "D", "value": "交叉驗證 (Cross Validation)" }
      ],
      "answer": "B",
      "explanation": "標記化處理 (Tokenization) 是將文本數據拆分為基本單元（如詞或子詞），這是讓語言模型能夠處理與理解文本的重要基礎步驟。[11]",
      "score": 2,
      "tags": ["技術概念", "Tokenization"]
    },
    {
      "id": "q9",
      "type": "single_choice",
      "questionText": "生成式模型在處理文本時，需將拆分好的基本單元轉換為神經網路可理解的數值形式或多維矩陣。此過程稱為？",
      "options": [
        { "key": "A", "value": "資料清洗 (Data Cleaning)" },
        { "key": "B", "value": "降維 (Dimensionality Reduction)" },
        { "key": "C", "value": "向量化表示 (Vectorization)" },
        { "key": "D", "value": "提示工程 (Prompt Engineering)" }
      ],
      "answer": "C",
      "explanation": "向量化表示 (Vectorization) 是指將文本或其他數據轉換為數值形式（向量），從而適應深度學習模型的數學運算需求。[11]",
      "score": 2,
      "tags": ["技術概念", "Vectorization"]
    },
    {
      "id": "q10",
      "type": "single_choice",
      "questionText": "在使用生成式 AI 進行推理（Inference）時，哪一個參數主要用來控制生成內容的「隨機性」與「創造力」，數值越高生成的內容越具創意？",
      "options": [
        { "key": "A", "value": "學習率 (Learning Rate)" },
        { "key": "B", "value": "溫度參數 (Temperature Parameter)" },
        { "key": "C", "value": "丟棄率 (Dropout Rate)" },
        { "key": "D", "value": "批次大小 (Batch Size)" }
      ],
      "answer": "B",
      "explanation": "溫度參數 (Temperature Parameter) 用於控制生成內容的隨機性。低溫度值會生成較保守、確定的內容，高溫度值則生成更具創意與多樣性的內容。[11, 12]",
      "score": 2,
      "tags": ["推理機制", "溫度參數"]
    },
    {
      "id": "q11",
      "type": "single_choice",
      "questionText": "在推理階段，為平衡生成品質與多樣性，系統僅從「累積機率達到某一特定閾值（如 0.9）」的選項中進行隨機採樣。此採樣機制稱為？",
      "options": [
        { "key": "A", "value": "核採樣 (Nucleus Sampling / Top-p)" },
        { "key": "B", "value": "頂部採樣 (Top-k Sampling)" },
        { "key": "C", "value": "貪婪搜索 (Greedy Search)" },
        { "key": "D", "value": "波束搜索 (Beam Search)" }
      ],
      "answer": "A",
      "explanation": "核採樣 (Nucleus Sampling) 是選擇累積機率達到某一閾值（如 0.9）的選項進行採樣，動態調整候選詞數量，靈活平衡品質與隨機性。[12]",
      "score": 2,
      "tags": ["推理機制", "核採樣"]
    },
    {
      "id": "q12",
      "type": "single_choice",
      "questionText": "大型語言模型（如 GPT 系列）能展現強大語言理解與生成能力，有效處理長距離依賴關係，主要歸功於下列哪一種網路架構與機制？",
      "options": [
        { "key": "A", "value": "卷積神經網路 (CNN) 的池化機制" },
        { "key": "B", "value": "K-均值 (K-Means) 分群演算法" },
        { "key": "C", "value": "Transformer 架構與自注意力機制 (Self-Attention)" },
        { "key": "D", "value": "決策樹的資訊增益 (Information Gain)" }
      ],
      "answer": "C",
      "explanation": "Transformer 架構中的自注意力機制 (Self-Attention) 有助於處理序列數據中的長距離依賴關係，並有效學習內部結構，是當今大型語言模型的核心基礎。[11, 13]",
      "score": 2,
      "tags": ["技術概念", "Transformer"]
    },
    {
      "id": "q13",
      "type": "single_choice",
      "questionText": "Midjourney 能夠生成高品質且細節豐富的圖像。其背後的核心生成技術，是透過「逐步向數據添加高斯雜訊，再透過神經網路反向去除雜訊」來重建影像，此技術稱為？",
      "options": [
        { "key": "A", "value": "變分自編碼器 (VAE)" },
        { "key": "B", "value": "擴散模型 (Diffusion Models)" },
        { "key": "C", "value": "生成對抗網路 (GAN)" },
        { "key": "D", "value": "自迴歸模型 (Autoregressive Models)" }
      ],
      "answer": "B",
      "explanation": "擴散模型 (Diffusion Models) 透過逐步添加雜訊及反向去噪的過程來重建影像，在圖像生成應用中展現極高的準確性與自然感。[13, 14]",
      "score": 2,
      "tags": ["生成式AI", "擴散模型"]
    },
    {
      "id": "q14",
      "type": "single_choice",
      "questionText": "「生成對抗網路 (GAN)」是高品質圖像生成的另一項重要技術。其運作核心主要是由哪兩個神經網路組成並相互競爭？",
      "options": [
        { "key": "A", "value": "生成器 (Generator) 與 鑑別器 (Discriminator)" },
        { "key": "B", "value": "編碼器 (Encoder) 與 解碼器 (Decoder)" },
        { "key": "C", "value": "演員 (Actor) 與 評論家 (Critic)" },
        { "key": "D", "value": "主節點 (Master Node) 與 工作節點 (Worker Node)" }
      ],
      "answer": "A",
      "explanation": "GAN 技術透過生成器（試圖製造逼真假資料）與鑑別器（試圖分辨真偽）之間的相互對抗訓練，最終使得生成的內容極具真實感。[14, 15]",
      "score": 2,
      "tags": ["生成式AI", "GAN"]
    },
    {
      "id": "q15",
      "type": "single_choice",
      "questionText": "關於變分自編碼器 (VAE) 的架構，下列敘述何者正確？",
      "options": [
        { "key": "A", "value": "利用鑑別器來計算輸入資料的分類概率" },
        { "key": "B", "value": "其架構僅包含單一的自注意力層" },
        { "key": "C", "value": "包含編碼器將資料壓縮為潛在空間分佈，再由解碼器從該空間採樣並重建資料" },
        { "key": "D", "value": "逐步向圖像添加雜訊再進行反向去噪" }
      ],
      "answer": "C",
      "explanation": "VAE 利用編碼器將輸入映射到一個機率分佈的潛在空間，並由解碼器進行重建，這種結構使其能提供穩定且多樣的機率生成方法。[13, 15]",
      "score": 2,
      "tags": ["生成式AI", "VAE"]
    },
    {
      "id": "q16",
      "type": "single_choice",
      "questionText": "為了使大型語言模型在訓練後期能更加貼近人類價值觀、偏好與安全準則，業界廣泛採用了哪一種結合人類評價的微調技術？",
      "options": [
        { "key": "A", "value": "無監督聚類 (Unsupervised Clustering)" },
        { "key": "B", "value": "聯邦學習 (Federated Learning)" },
        { "key": "C", "value": "主成分分析 (PCA)" },
        { "key": "D", "value": "人類回饋強化學習 (RLHF)" }
      ],
      "answer": "D",
      "explanation": "人類回饋強化學習 (RLHF) 透過引入人類的評價作為獎勵信號來優化模型，使生成結果更加安全、精確且貼近用戶需求。[13]",
      "score": 2,
      "tags": ["技術概念", "RLHF"]
    },
    {
      "id": "q17",
      "type": "single_choice",
      "questionText": "用戶透過精確調整輸入指令的結構與上下文，引導生成式 AI 模型產出更符合特定風格或任務預期的內容。這項技術與實踐被稱為？",
      "options": [
        { "key": "A", "value": "提示工程 (Prompt Engineering)" },
        { "key": "B", "value": "模型量化 (Quantization)" },
        { "key": "C", "value": "資料清洗 (Data Cleaning)" },
        { "key": "D", "value": "模型剪枝 (Model Pruning)" }
      ],
      "answer": "A",
      "explanation": "提示工程 (Prompt Engineering) 是指透過設計與優化輸入給模型的提示詞，來有效提升模型生成結果的精準度與適用性。[13, 16, 17]",
      "score": 2,
      "tags": ["技術應用", "提示工程"]
    },
    {
      "id": "q18",
      "type": "single_choice",
      "questionText": "企業無需建置高階硬體，即可透過雲端平台訂閱或 API 呼叫，存取高效能的生成式 AI 工具。這種商業模式稱為什麼？",
      "options": [
        { "key": "A", "value": "在地化部署 (On-premise)" },
        { "key": "B", "value": "AI 即服務 (AI as a Service, AIaaS)" },
        { "key": "C", "value": "基礎設施即服務 (IaaS)" },
        { "key": "D", "value": "硬體即服務 (HaaS)" }
      ],
      "answer": "B",
      "explanation": "AI 即服務 (AIaaS) 透過雲端平台提供 API 或外掛程式，讓用戶能低門檻、高效率地存取與整合強大的 AI 工具。[10, 16]",
      "score": 2,
      "tags": ["商業模式", "AIaaS"]
    },
    {
      "id": "q19",
      "type": "single_choice",
      "questionText": "在 AI 專案導入初期，為了在真實場景中以低成本且風險可控的方式驗證技術效果，企業通常會進行下列何項工作？",
      "options": [
        { "key": "A", "value": "進行小規模的概念驗證 (POC) 試點應用" },
        { "key": "B", "value": "直接全面替換公司的核心資料庫" },
        { "key": "C", "value": "發布全球公測版本" },
        { "key": "D", "value": "裁撤既有的傳統技術團隊" }
      ],
      "answer": "A",
      "explanation": "在初始階段，企業應將資源集中於小範圍的試點項目 (POC)，透過低成本且風險可控的方式驗證 AI 技術在真實場景中的可行性與效果。[18, 19]",
      "score": 2,
      "tags": ["導入規劃", "POC"]
    },
    {
      "id": "q20",
      "type": "single_choice",
      "questionText": "企業評估生成式 AI 專案的財務可行性時，為納入現金流時間分佈的考量，常計算下列哪兩項財務指標？",
      "options": [
        { "key": "A", "value": "精確率 (Precision) 與 召回率 (Recall)" },
        { "key": "B", "value": "淨現值 (NPV) 與 內部報酬率 (IRR)" },
        { "key": "C", "value": "BLEU 與 ROUGE" },
        { "key": "D", "value": "GPU 使用率 與 延遲 (Latency)" }
      ],
      "answer": "B",
      "explanation": "計算 ROI 時，會使用回本時間預估模型並納入現金流分析，計算淨現值 (NPV) 與內部報酬率 (IRR)，以評估方案的財務可行性與長期收益潛力。[20]",
      "score": 2,
      "tags": ["導入評估", "ROI計算"]
    },
    {
      "id": "q21",
      "type": "single_choice",
      "questionText": "在訓練自迴歸生成式語言模型時，最常被用來評估模型「預測下一個詞語的機率分佈」與「真實標籤」之間差異的損失函數是？",
      "options": [
        { "key": "A", "value": "均方誤差 (MSE)" },
        { "key": "B", "value": "平滑 L1 損失 (Smooth L1 Loss)" },
        { "key": "C", "value": "餘弦相似度 (Cosine Similarity)" },
        { "key": "D", "value": "交叉熵損失 (Cross-Entropy Loss)" }
      ],
      "answer": "D",
      "explanation": "在自迴歸模型的訓練中，最常用的損失函數為交叉熵損失 (Cross-Entropy Loss)，它能有效衡量模型預測下一個詞的機率分佈與真實標籤間的差異。[21]",
      "score": 2,
      "tags": ["模型訓練", "損失函數"]
    },
    {
      "id": "q22",
      "type": "single_choice",
      "questionText": "在神經網路訓練過程中，為提升模型收斂速度並根據不同的參數規模自適應調整學習步長，實務上對於大型語言模型最常選用的優化器 (Optimizer) 為何？",
      "options": [
        { "key": "A", "value": "AdamW 或 LAMB" },
        { "key": "B", "value": "K-Means" },
        { "key": "C", "value": "SVM" },
        { "key": "D", "value": "決策樹" }
      ],
      "answer": "A",
      "explanation": "AdamW 和 LAMB 是大型語言模型訓練中常用的優化器，它們能針對不同模型大小自適應調整學習率，穩定並加速收斂過程。[21]",
      "score": 2,
      "tags": ["模型訓練", "優化器"]
    },
    {
      "id": "q23",
      "type": "single_choice",
      "questionText": "在訓練大型神經網路時，為了防止模型過度學習訓練數據的細節而導致泛化能力下降（即過擬合），常在訓練中隨機關閉部分神經元。此正則化技術稱為？",
      "options": [
        { "key": "A", "value": "核採樣 (Nucleus Sampling)" },
        { "key": "B", "value": "早停策略 (Early Stopping)" },
        { "key": "C", "value": "Dropout" },
        { "key": "D", "value": "資料清洗 (Data Cleaning)" }
      ],
      "answer": "C",
      "explanation": "Dropout 是一種經典的正則化技術，透過在訓練時隨機丟棄（關閉）部分神經元，強迫網路學習更穩健的特徵，有效防止過擬合。[21]",
      "score": 2,
      "tags": ["模型訓練", "正則化"]
    },
    {
      "id": "q24",
      "type": "single_choice",
      "questionText": "在訓練生成式大型模型時，採用「混合精度訓練 (Mixed Precision Training)」技術的主要優勢為何？",
      "options": [
        { "key": "A", "value": "自動清除資料集中的敏感個資" },
        { "key": "B", "value": "在不影響最終精度的前提下，大幅減少計算資源消耗並加速訓練" },
        { "key": "C", "value": "保證模型產生的文本絕對真實不造假" },
        { "key": "D", "value": "強制提升模型輸出結果的長度" }
      ],
      "answer": "B",
      "explanation": "混合精度訓練有助於在不影響模型最終精度的情況下，顯著減少記憶體與計算資源的消耗，並加速模型的訓練速度。[21, 22]",
      "score": 2,
      "tags": ["模型訓練", "混合精度訓練"]
    },
    {
      "id": "q25",
      "type": "single_choice",
      "questionText": "在設定生成式語言模型的驗證基準時，通常會採用哪一組量化標準指標，來客觀評估模型生成文本的品質、相似度與流暢性？",
      "options": [
        { "key": "A", "value": "NPV、IRR" },
        { "key": "B", "value": "GDPR、CCPA" },
        { "key": "C", "value": "BLEU、ROUGE、Perplexity" },
        { "key": "D", "value": "SVM、KNN、K-Means" }
      ],
      "answer": "C",
      "explanation": "評估生成式 AI 語言模型效能時，BLEU、ROUGE 與 Perplexity 是最常採用的量化指標，用以衡量生成內容的流暢度與品質。[22]",
      "score": 2,
      "tags": ["模型評估", "量化指標"]
    },
    {
      "id": "q26",
      "type": "single_choice",
      "questionText": "在模型準備部署前，為了測試模型在處理極端、稀有或高負載異常數據情境下的穩定性，必須進行何種測試？",
      "options": [
        { "key": "A", "value": "用戶介面 (UI) 色彩測試" },
        { "key": "B", "value": "跨部門滿意度調查" },
        { "key": "C", "value": "邊界檢查 (Boundary Testing)" },
        { "key": "D", "value": "程式碼語法高亮測試" }
      ],
      "answer": "C",
      "explanation": "邊界檢查 (Boundary Testing) 的目的在於測試模型運行的極限，確保其在面對稀有、異常或高負載數據時具備足夠的穩定性與應對能力。[23]",
      "score": 2,
      "tags": ["效能驗證", "邊界檢查"]
    },
    {
      "id": "q27",
      "type": "single_choice",
      "questionText": "模型上線營運一段時間後，因真實業務場景的變化或用戶行為改變，導致「輸入模型的新數據分佈」偏離了原本的訓練數據，進而造成預測準確率下降。這種現象稱為？",
      "options": [
        { "key": "A", "value": "梯度爆炸 (Gradient Explosion)" },
        { "key": "B", "value": "數據漂移 (Data Drift)" },
        { "key": "C", "value": "模式崩潰 (Mode Collapse)" },
        { "key": "D", "value": "災難性遺忘 (Catastrophic Forgetting)" }
      ],
      "answer": "B",
      "explanation": "數據漂移 (Data Drift) 是指隨著時間推移，業務環境導致輸入數據分佈發生變化，使得原本訓練好的模型效能下降，此時需進行重新訓練。[24, 25]",
      "score": 2,
      "tags": ["營運管理", "數據漂移"]
    },
    {
      "id": "q28",
      "type": "single_choice",
      "questionText": "為確保生成式 AI 模型在動態環境中保持最佳效能，當系統監控到預測錯誤率上升達到警戒值時，最理想的自動化應對機制為何？",
      "options": [
        { "key": "A", "value": "立即關閉伺服器並通知客服" },
        { "key": "B", "value": "直接將所有舊數據刪除以節省空間" },
        { "key": "C", "value": "啟動自動化重新訓練管道 (Retraining Pipeline)，結合新數據微調模型並部署" },
        { "key": "D", "value": "將模型溫度參數強制設定為零" }
      ],
      "answer": "C",
      "explanation": "構建自動化的重新訓練管道 (Retraining Pipeline) 可以在監控到效能下降時，自動觸發訓練更新並部署新模型，有效應對數據漂移問題並減少人工干預。[25]",
      "score": 2,
      "tags": ["營運管理", "重新訓練"]
    },
    {
      "id": "q29",
      "type": "single_choice",
      "questionText": "在 AI 導入計畫的「敏感性分析 (Sensitivity Analysis)」階段，主要目的是為了什麼？",
      "options": [
        { "key": "A", "value": "搜尋數據庫中是否存在員工的敏感個資" },
        { "key": "B", "value": "模擬不同市場條件或成本變動對方案收益的影響，以識別風險與機會" },
        { "key": "C", "value": "檢測神經網路對極端雜訊輸入的崩潰情況" },
        { "key": "D", "value": "測試操作介面是否對色盲用戶足夠友善" }
      ],
      "answer": "B",
      "explanation": "財務評估中的敏感性分析，能有效模擬各種變數（如市場條件、業務情境或成本波動）對預期收益的影響，幫助決策者制定更穩健的投資策略。[20, 24]",
      "score": 2,
      "tags": ["導入評估", "敏感性分析"]
    },
    {
      "id": "q30",
      "type": "single_choice",
      "questionText": "將文字、圖像、音訊等多種資料格式結合，例如給定一段文字即可生成對應的圖片或影片（如 DALL-E），這類跨越單一媒體形式的生成式 AI 技術被稱為什麼？",
      "options": [
        { "key": "A", "value": "單模態生成 (Uni-modal Generation)" },
        { "key": "B", "value": "強化生成 (Reinforcement Generation)" },
        { "key": "C", "value": "純文字自迴歸模型 (Text-only Autoregressive Model)" },
        { "key": "D", "value": "多模態生成 (Multi-modal Generation)" }
      ],
      "answer": "D",
      "explanation": "多模態生成 (Multi-modal) 是指將文本、圖像、音訊等多種模態結合的技術，例如 DALL-E 將文本描述轉化為圖像，開創了更豐富的應用場景。[10, 12, 13]",
      "score": 2,
      "tags": ["生成式AI", "多模態"]
    },
    {
      "id": "q31",
      "type": "single_choice",
      "questionText": "為了降低訓練數據中的偏見可能導致系統產生不公平的輸出，在建立模型時最重要的根本防範措施為何？",
      "options": [
        { "key": "A", "value": "確保訓練數據具備多樣性與代表性，並在過程中採用去偏見技術" },
        { "key": "B", "value": "禁止不同國籍的用戶使用該系統" },
        { "key": "C", "value": "將所有與人類屬性相關的特徵直接刪除" },
        { "key": "D", "value": "僅依賴少量專家的主觀判定來過濾最終結果" }
      ],
      "answer": "A",
      "explanation": "模型偏見多源自訓練資料的不平衡。確保訓練數據的多樣性，並在過程中結合去偏見技術與公平性測試，是防範倫理偏見最直接有效的方法。[23, 26]",
      "score": 2,
      "tags": ["AI倫理", "偏見防範"]
    },
    {
      "id": "q32",
      "type": "single_choice",
      "questionText": "在 AI 的風險評估實務中，「風險矩陣 (Risk Matrix)」是非常重要的分析工具。它主要是將哪兩個維度進行交叉對比，以判定風險的優先處理級別？",
      "options": [
        { "key": "A", "value": "發生概率 與 影響程度" },
        { "key": "B", "value": "開發時間 與 設備成本" },
        { "key": "C", "value": "模型參數大小 與 網路頻寬" },
        { "key": "D", "value": "預期營收 與 客戶數量" }
      ],
      "answer": "A",
      "explanation": "風險矩陣透過將風險的「發生概率」與其「影響程度」進行交叉對比，幫助決策者直觀了解各類風險的嚴重性與權重，從而優先處理高風險問題。[27]",
      "score": 2,
      "tags": ["風險評估", "風險矩陣"]
    },
    {
      "id": "q33",
      "type": "single_choice",
      "questionText": "為了確保生成內容的合法性與過程透明化，企業引入「可解釋性 AI 技術」，詳細記錄數據輸入與處理邏輯，確保在出現問題時能迅速找到根源。這屬於哪一種風險管理概念？",
      "options": [
        { "key": "A", "value": "風險轉移" },
        { "key": "B", "value": "風險迴避" },
        { "key": "C", "value": "風險溯源" },
        { "key": "D", "value": "對抗性攻擊" }
      ],
      "answer": "C",
      "explanation": "風險溯源要求確保數據來源合法，並採用可解釋性 AI 技術讓模型生成過程具備可追溯性，確保在出現偏差時能迅速追溯問題根源。[28]",
      "score": 2,
      "tags": ["風險管理", "風險溯源"]
    },
    {
      "id": "q34",
      "type": "single_choice",
      "questionText": "若企業評估某一生成式 AI 應用的技術尚未成熟，且可能導致重大損失，因此決定「暫緩開發該專案」，完全避免該風險的發生。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險接受 (Risk Acceptance)" },
        { "key": "B", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "C", "value": "風險轉移 (Risk Transfer)" },
        { "key": "D", "value": "風險迴避 (Risk Avoidance)" }
      ],
      "answer": "D",
      "explanation": "風險迴避適用於技術不成熟或可能導致重大損害的場景，透過暫緩開發或停止高風險應用，從根本上完全避免風險發生。[29]",
      "score": 2,
      "tags": ["風險管理", "風險迴避"]
    },
    {
      "id": "q35",
      "type": "single_choice",
      "questionText": "針對生成內容可能包含的不當訊息，企業制定明確政策並設置嚴格的「內容審查與過濾機制」，以降低風險發生的機率或減輕其影響。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "B", "value": "風險接受 (Risk Acceptance)" },
        { "key": "C", "value": "風險迴避 (Risk Avoidance)" },
        { "key": "D", "value": "風險溯源 (Risk Traceability)" }
      ],
      "answer": "A",
      "explanation": "風險緩解是透過設置安全控制措施（如內容過濾與人工審查），以降低潛在風險發生的機率或減輕其造成的負面影響。[29]",
      "score": 2,
      "tags": ["風險管理", "風險緩解"]
    },
    {
      "id": "q36",
      "type": "single_choice",
      "questionText": "企業透過購買相關保險，或與外部雲端安全服務供應商簽署合約，將 AI 系統營運的部分潛在資安責任交由第三方承擔。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "B", "value": "風險接受 (Risk Acceptance)" },
        { "key": "C", "value": "風險迴避 (Risk Avoidance)" },
        { "key": "D", "value": "風險轉移 (Risk Transfer)" }
      ],
      "answer": "D",
      "explanation": "風險轉移是指透過購買保險或外包合約，將部分或全部的風險與責任轉移給第三方承擔，以分散自身壓力。[29, 30]",
      "score": 2,
      "tags": ["風險管理", "風險轉移"]
    },
    {
      "id": "q37",
      "type": "single_choice",
      "questionText": "當某項 AI 應用的風險影響有限或無法完全避免時，企業在評估自身容忍度後，決定繼續推進並「制定應急計畫」來處理突發狀況。這屬於哪一種風險應對策略？",
      "options": [
        { "key": "A", "value": "風險轉移 (Risk Transfer)" },
        { "key": "B", "value": "風險接受 (Risk Acceptance)" },
        { "key": "C", "value": "風險緩解 (Risk Mitigation)" },
        { "key": "D", "value": "風險迴避 (Risk Avoidance)" }
      ],
      "answer": "B",
      "explanation": "風險接受是指企業基於現實條件與容忍度，理性選擇接受該風險，並制定詳細的應急準備方案以達成風險與效益的平衡。[29]",
      "score": 2,
      "tags": ["風險管理", "風險接受"]
    },
    {
      "id": "q38",
      "type": "single_choice",
      "questionText": "為保障全球營運時的資料隱私與合規性，企業在處理歐洲與美國加州用戶資料時，必須確保生成式 AI 模型的開發與應用符合哪兩項具代表性的法規？",
      "options": [
        { "key": "A", "value": "ISO 9001 與 ISO 14001" },
        { "key": "B", "value": "GDPR (一般資料保護規則) 與 CCPA (加州消費者隱私法案)" },
        { "key": "C", "value": "Basel III 與 SOX 法案" },
        { "key": "D", "value": "GAAP 與 IFRS" }
      ],
      "answer": "B",
      "explanation": "生成式 AI 在處理個人資料時，必須嚴格遵守資料隱私保護規範，歐盟的 GDPR 與美國加州的 CCPA 是目前最具代表性的隱私保護法規。[26, 31]",
      "score": 2,
      "tags": ["法規遵循", "隱私保護"]
    },
    {
      "id": "q39",
      "type": "single_choice",
      "questionText": "在大型語言模型的開發過程中，除了自動化檢測外，為確保生成內容的準確性、合規性與安全性，常結合人類專業知識在關鍵節點進行審核。此種機制被稱為？",
      "options": [
        { "key": "A", "value": "全自動化推理 (Fully Automated Inference)" },
        { "key": "B", "value": "對抗性攻擊 (Adversarial Attack)" },
        { "key": "C", "value": "人機協作機制 (Human-in-the-loop)" },
        { "key": "D", "value": "非監督式分群 (Unsupervised Clustering)" }
      ],
      "answer": "C",
      "explanation": "人機協作機制 (Human-in-the-loop) 結合人類專家知識與 AI 效率，透過人工審核與干預來降低生成內容錯誤或不當帶來的潛在風險。[32]",
      "score": 2,
      "tags": ["風險管理", "人機協作"]
    },
    {
      "id": "q40",
      "type": "single_choice",
      "questionText": "惡意使用者透過特製的提示詞（如提示注入 Prompt Injection），試圖繞過系統限制，誘導生成式 AI 洩露敏感機密或產出不當言論。此類安全性風險屬於？",
      "options": [
        { "key": "A", "value": "災難性遺忘 (Catastrophic Forgetting)" },
        { "key": "B", "value": "對抗性攻擊 (Adversarial Attack)" },
        { "key": "C", "value": "數據漂移 (Data Drift)" },
        { "key": "D", "value": "模式崩潰 (Mode Collapse)" }
      ],
      "answer": "B",
      "explanation": "對抗性攻擊（包含提示詞攻擊）是指攻擊者利用精心設計的輸入來操控模型行為，企圖使模型繞過安全守則並洩露隱私或生成惡意內容。[26, 33]",
      "score": 2,
      "tags": ["風險管理", "對抗性攻擊"]
    },
    {
      "id": "q41",
      "type": "single_choice",
      "questionText": "為保護資料在訓練過程中的隱私，防止攻擊者藉由模型輸出推斷出特定個人的敏感資訊，企業可導入哪一項技術來為數據添加適度雜訊？",
      "options": [
        { "key": "A", "value": "差分隱私技術 (Differential Privacy)" },
        { "key": "B", "value": "提示工程 (Prompt Engineering)" },
        { "key": "C", "value": "網格搜索 (Grid Search)" },
        { "key": "D", "value": "邊界檢查 (Boundary Testing)" }
      ],
      "answer": "A",
      "explanation": "差分隱私技術 (Differential Privacy) 透過在資料或梯度中加入數學雜訊，能確保模型分析整體趨勢的同時，極大化保護個人隱私不被外洩。[31, 33]",
      "score": 2,
      "tags": ["風險管理", "差分隱私"]
    },
    {
      "id": "q42",
      "type": "single_choice",
      "questionText": "為了推動企業內部的「風險文化」，下列哪一項做法是有效強化基層員工風險意識的策略？",
      "options": [
        { "key": "A", "value": "完全禁止員工討論任何 AI 系統可能的缺陷" },
        { "key": "B", "value": "將所有風險管理責任集中於唯一的資安主管" },
        { "key": "C", "value": "裁罰所有在測試階段發現模型錯誤的員工" },
        { "key": "D", "value": "建立風險報告機制與獎勵政策，鼓勵員工主動報告風險並提出改進建議" }
      ],
      "answer": "D",
      "explanation": "良好的風險文化強調全體參與。企業應透過教育培訓與建立風險報告的獎勵機制，鼓勵員工主動識別潛在風險並參與改進。[28]",
      "score": 2,
      "tags": ["風險管理", "風險文化"]
    },
    {
      "id": "q43",
      "type": "single_choice",
      "questionText": "生成式 AI 可能「一本正經地胡說八道」，生成看似合理但實際上不準確、虛構或毫無根據的內容。此種挑戰被廣泛稱為什麼？",
      "options": [
        { "key": "A", "value": "數據漂移 (Data Drift)" },
        { "key": "B", "value": "AI 幻覺 (AI Hallucinations)" },
        { "key": "C", "value": "對抗性攻擊 (Adversarial Attack)" },
        { "key": "D", "value": "反向工程 (Reverse Engineering)" }
      ],
      "answer": "B",
      "explanation": "AI 幻覺 (AI Hallucinations) 是指模型生成看似合理但實際上不準確、虛構或毫無根據的內容，嚴重影響內容的真實性與可靠性。[12]",
      "score": 2,
      "tags": ["風險管理", "AI幻覺"]
    },
    {
      "id": "q44",
      "type": "single_choice",
      "questionText": "當企業準備將現有的開源語言模型應用於專屬的業務（如特定產品的自動化客服）時，為了讓模型適應該領域的專業術語與知識，通常會進行下列何種處理？",
      "options": [
        { "key": "A", "value": "模型微調 (Fine-tuning)" },
        { "key": "B", "value": "從頭開始進行預訓練 (Pre-training from scratch)" },
        { "key": "C", "value": "只進行模型壓縮 (Model Compression)" },
        { "key": "D", "value": "採用線性迴歸替代語言模型" }
      ],
      "answer": "A",
      "explanation": "利用預訓練模型，針對特定領域或任務的資料進行進一步的訓練調整，以提升專業領域表現，此技術稱為模型微調 (Fine-tuning)。[13, 16, 22]",
      "score": 2,
      "tags": ["技術概念", "微調"]
    },
    {
      "id": "q45",
      "type": "single_choice",
      "questionText": "在 AI 的運營與監控中，為了在模型訓練時找出最佳的超參數（Hyperparameter）組合，實務上會使用哪一種方法來測試多種模型配置？",
      "options": [
        { "key": "A", "value": "標記化處理 (Tokenization)" },
        { "key": "B", "value": "網格搜索 (Grid Search)" },
        { "key": "C", "value": "模型量化 (Quantization)" },
        { "key": "D", "value": "差分隱私 (Differential Privacy)" }
      ],
      "answer": "B",
      "explanation": "網格搜索 (Grid Search) 是一種窮舉搜索方法，透過測試多種超參數組合，來找出並選擇生成品質最佳的模型配置方案。[21]",
      "score": 2,
      "tags": ["模型訓練", "網格搜索"]
    },
    {
      "id": "q46",
      "type": "single_choice",
      "questionText": "為了提升生成式 AI 在資源有限環境（如手機等邊緣計算設備）中的執行效率，開發者常使用哪一項技術來減少模型的計算與儲存需求？",
      "options": [
        { "key": "A", "value": "模型壓縮與量化 (Model Compression & Quantization)" },
        { "key": "B", "value": "增加 Transformer 層數" },
        { "key": "C", "value": "調高溫度參數 (Temperature)" },
        { "key": "D", "value": "採用全自動化設計 (Fully Automated Design)" }
      ],
      "answer": "A",
      "explanation": "模型壓縮與量化技術能有效減少生成式 AI 工具的計算和儲存需求，使其能夠在資源有限的邊緣設備或移動設備中順利運行。[12, 14, 22, 34]",
      "score": 2,
      "tags": ["模型優化", "模型壓縮"]
    },
    {
      "id": "q47",
      "type": "single_choice",
      "questionText": "在生成式 AI 導入規劃的「設計（確認 AI生成規格）」階段，第一步應為？",
      "options": [
        { "key": "A", "value": "撰寫底層核心演算法" },
        { "key": "B", "value": "確認導入最終目標並設立可量化的 KPI" },
        { "key": "C", "value": "強制遣散原有員工" },
        { "key": "D", "value": "公開發布所有測試數據" }
      ],
      "answer": "B",
      "explanation": "在設計階段，企業應明確商業目標，讓 AI 方案與公司策略保持一致，並設立可量化的成功標準 (KPI)，以便於後續進度檢視與成效衡量。[35]",
      "score": 2,
      "tags": ["導入規劃", "設計階段"]
    },
    {
      "id": "q48",
      "type": "single_choice",
      "questionText": "在訓練模型時，為了避免模型過度學習訓練集的細節而導致泛化能力下降，通常會在驗證集誤差開始上升時停止迭代。這項防範過擬合的技術稱為？",
      "options": [
        { "key": "A", "value": "梯度消失" },
        { "key": "B", "value": "早停策略 (Early Stopping)" },
        { "key": "C", "value": "模型剪枝" },
        { "key": "D", "value": "標記化處理" }
      ],
      "answer": "B",
      "explanation": "早停策略（Early Stopping）是監控模型在驗證集的表現，當效能不再提升甚至開始惡化時，提前終止訓練過程，是防止過擬合的常見手段。[21]",
      "score": 2,
      "tags": ["模型訓練", "早停策略"]
    },
    {
      "id": "q49",
      "type": "single_choice",
      "questionText": "若企業開發一款自動生成行銷文案的工具，為了讓模型能在每次產出時展現「高度的多樣性與創意」，開發者應如何設定溫度參數 (Temperature)？",
      "options": [
        { "key": "A", "value": "將溫度參數設為較低值" },
        { "key": "B", "value": "將溫度參數設為較高值" },
        { "key": "C", "value": "將溫度參數固定為 0" },
        { "key": "D", "value": "溫度參數無法改變文字生成的多樣性" }
      ],
      "answer": "B",
      "explanation": "溫度參數控制生成內容的隨機性，高溫度值會促使模型生成更具創意與多樣性的內容，適合用於需要靈感啟發的行銷文案撰寫。[11, 12]",
      "score": 2,
      "tags": ["推理機制", "溫度參數"]
    },
    {
      "id": "q50",
      "type": "single_choice",
      "questionText": "在評估生成式 AI 導入方案時，系統架構需具備「系統可擴展性」。這代表什麼意義？",
      "options": [
        { "key": "A", "value": "架構需具備彈性，能隨著應用規模與數據量的增加進行擴展與調整" },
        { "key": "B", "value": "系統能支援無限多種程式語言" },
        { "key": "C", "value": "軟體能自動將錯誤代碼隱藏" },
        { "key": "D", "value": "企業不需要再購買任何硬體" }
      ],
      "answer": "A",
      "explanation": "系統可擴展性（Scalability）指的是基礎架構（如伺服器、雲端空間）必須具備足夠的彈性，當 AI 應用的需求或數據規模成長時，系統能夠順利擴展以維持穩定運行。[36]",
      "score": 2,
      "tags": ["導入評估", "系統可擴展性"]
    }
  ]
}